<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content="Minimalist Data Wrangling with Python" name="citation_title" />
<meta content="Marek Gagolewski" name="citation_author" />
<meta content="2023" name="citation_date" />
<meta content="2023" name="citation_publication_date" />
<meta content="https://datawranglingpy.gagolewski.com/datawranglingpy.pdf" name="citation_pdf_url" />
<meta content="https://datawranglingpy.gagolewski.com/" name="citation_public_url" />
<meta content="10.5281/zenodo.6451068" name="citation_doi" />
<meta content="Minimalist Data Wrangling with Python is envisaged as a student's first introduction to data science, providing a high-level overview as well as discussing key concepts in detail. We explore methods for cleaning data gathered from different sources, transforming, selecting, and extracting features, performing exploratory data analysis and dimensionality reduction, identifying naturally occurring data clusters, modelling patterns in data, comparing data between groups, and reporting the results. This textbook is a non-profit project. Its online and PDF versions are freely available at https://datawranglingpy.gagolewski.com/." name="citation_abstract" />
<meta content="summary" name="twitter:card" />
<meta content="Minimalist Data Wrangling with Python" name="twitter:title" />
<meta content="Minimalist Data Wrangling with Python" name="og:title" />
<meta content="Minimalist Data Wrangling with Python is envisaged as a student's first introduction to data science, providing a high-level overview as well as discussing key concepts in detail. We explore methods for cleaning data gathered from different sources, transforming, selecting, and extracting features, performing exploratory data analysis and dimensionality reduction, identifying naturally occurring data clusters, modelling patterns in data, comparing data between groups, and reporting the results. This textbook is a non-profit project. Its online and PDF versions are freely available at https://datawranglingpy.gagolewski.com/." name="twitter:description" />
<meta content="Minimalist Data Wrangling with Python is envisaged as a student's first introduction to data science, providing a high-level overview as well as discussing key concepts in detail. We explore methods for cleaning data gathered from different sources, transforming, selecting, and extracting features, performing exploratory data analysis and dimensionality reduction, identifying naturally occurring data clusters, modelling patterns in data, comparing data between groups, and reporting the results. This textbook is a non-profit project. Its online and PDF versions are freely available at https://datawranglingpy.gagolewski.com/." name="og:description" />
<meta content="gagolews/datawranglingpy" name="og:site_name" />
<meta content="https://datawranglingpy.gagolewski.com/" name="og:url" />
<meta content="https://datawranglingpy.gagolewski.com/_images/cover.png" name="twitter:image" />
<meta content="https://datawranglingpy.gagolewski.com/_images/cover.png" name="og:image" />
<meta content="https://datawranglingpy.gagolewski.com/" name="DC.identifier" />
<meta content="Marek Gagolewski" name="DC.publisher" />
<meta content="INDEX,FOLLOW" name="robots" />
<meta content="book" name="og:type" />
<meta content="9780645571912" name="og:book:isbn" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="6. Continuous probability distributions" href="230-distribution.html" /><link rel="prev" title="4. Unidimensional numeric data and their empirical distribution" href="210-vector.html" />
        <link rel="canonical" href="https://datawranglingpy.gagolewski.com/chapter/220-transform-vector.html" />

    <link rel="shortcut icon" href="https://www.gagolewski.com/_static/img/datawranglingpy.png"/><!-- Generated with Sphinx 7.2.5 and Furo 2023.08.19 -->
        <title>5. Processing unidimensional data - Minimalist Data Wrangling with Python</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=cc2833c3" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --admonition-font-size: 95%;
  --admonition-title-font-size: 95%;
  --color-brand-primary: red;
  --color-brand-content: #CC3333;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --admonition-font-size: 95%;
  --admonition-title-font-size: 95%;
  --color-brand-primary: #ff2b53;
  --color-brand-content: #dd3333;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --admonition-font-size: 95%;
  --admonition-title-font-size: 95%;
  --color-brand-primary: #ff2b53;
  --color-brand-content: #dd3333;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Minimalist Data Wrangling with Python</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto colour theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky">
<div class="sidebar-logo-container">
  <a class="sidebar-brand" href="../index.html"><img class="sidebar-logo" src="https://www.gagolewski.com/_static/img/datawranglingpy.png" alt="Logo"/></a>
</div>

<span class="sidebar-brand-text">
<a class="sidebar-brand" href="../index.html">Minimalist Data Wrangling with Python</a>
</span>
<div class="sidebar-brand">
An open-access textbook<br />
by <a href='https://www.gagolewski.com/' style="display: contents">Marek Gagolewski</a><br />
v1.0.3.9011
</div>
<form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">About</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.gagolewski.com/">Author</a></li>
<li class="toctree-l1"><a class="reference external" href="https://datawranglingpy.gagolewski.com/datawranglingpy.pdf">This book in PDF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../order-paper-copy.html">Order a paper copy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/gagolews/datawranglingpy">Report bugs or typos (GitHub)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/gagolews/teaching-data">Datasets</a></li>
<li class="toctree-l1"><a class="reference external" href="https://deepr.gagolewski.com/">Deep R programming</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Start here</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="000-preface.html">Preface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introducing Python</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="110-setup.html">1. Getting started with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="120-scalar.html">2. Scalar types and control structures in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="130-sequential.html">3. Sequential and other types in Python</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Unidimensional data</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="210-vector.html">4. Unidimensional numeric data and their empirical distribution</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">5. Processing unidimensional data</a></li>
<li class="toctree-l1"><a class="reference internal" href="230-distribution.html">6. Continuous probability distributions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multidimensional data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="310-matrix.html">7. Multidimensional numeric data at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="320-transform-matrix.html">8. Processing multidimensional data</a></li>
<li class="toctree-l1"><a class="reference internal" href="330-relationship.html">9. Exploring relationships between variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Heterogeneous data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="410-data-frame.html">10. Introducing data frames</a></li>
<li class="toctree-l1"><a class="reference internal" href="420-categorical.html">11. Handling categorical data</a></li>
<li class="toctree-l1"><a class="reference internal" href="430-group-by.html">12. Processing data in groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="440-sql.html">13. Accessing databases</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other data types</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="510-text.html">14. Text data</a></li>
<li class="toctree-l1"><a class="reference internal" href="520-missingness.html">15. Missing, censored, and questionable data</a></li>
<li class="toctree-l1"><a class="reference internal" href="530-time-series.html">16. Time series</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="998-changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="999-bibliography.html">References</a></li>
</ul>

</div></div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="edit-this-page">
  <a class="muted-link" href="https://github.com/gagolews/datawranglingpy" title="Edit this page">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto colour theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section class="tex2jax_ignore mathjax_ignore" id="processing-unidimensional-data">
<span id="chap-transform-vector"></span><h1><span class="section-number">5. </span>Processing unidimensional data<a class="headerlink" href="#processing-unidimensional-data" title="Link to this heading">#</a></h1>
<blockquote>
<div><p><em>This open-access textbook
is, and will remain, freely available for everyone’s enjoyment
(also in <a class="reference external" href="https://datawranglingpy.gagolewski.com/datawranglingpy.pdf">PDF</a>;
a paper copy can also be <a class="reference internal" href="../order-paper-copy.html"><span class="doc std std-doc">ordered</span></a>).
It is a non-profit project. Although available online, it is a whole course,
and should be read from the beginning to the end.
Refer to the <a class="reference internal" href="000-preface.html#chap-preface"><span class="std std-ref">Preface</span></a> for general introductory remarks. Any
<a class="reference external" href="https://github.com/gagolews/datawranglingpy">bug/typo reports/fixes</a>
are appreciated. Make sure to check out
<a class="reference external" href="https://deepr.gagolewski.com/"><em>Deep R Programming</em></a>
<span id="id1">[<a class="reference internal" href="999-bibliography.html#id2" title="Gagolewski, M. (2023).  Deep R Programming. Zenodo. URL: https://deepr.gagolewski.com/, DOI: 10.5281/zenodo.7490464.">34</a>]</span> too.</em></p>
</div></blockquote>
<p>It is extremely rare for our datasets to bring interesting
and valid insights out of the box. The ones we are using
for illustrational purposes in the first part of our book have
already been curated. After all, this is an introductory course.
We need to build up the necessary skills and not overwhelm
the tireless reader with too much information all at once.
We learn simple things first, learn them well, and then we move to
more complex matters with a healthy level of confidence.</p>
<p>In real life, various <em>data cleansing</em> and <em>feature engineering</em>
techniques will need to be performed on data.
Most of them are based on the simple operations on vectors
that we cover in this chapter:</p>
<ul class="simple">
<li><p>summarising data (for example, computing the median or sum),</p></li>
<li><p>transforming values (applying mathematical operations on each element,
such as subtracting a scalar or taking the natural logarithm),</p></li>
<li><p>filtering (selecting or removing observations
that meet specific criteria,
e.g., those that are larger than the arithmetic mean ± 3 standard
deviations).</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><a class="reference internal" href="410-data-frame.html#chap-data-frame"><span class="std std-numref">Chapter 10</span></a> will be applying
the same operations on individual data frame columns.</p>
</div>
<section id="aggregating-numeric-data">
<span id="sec-aggregate"></span><h2><span class="section-number">5.1. </span>Aggregating numeric data<a class="headerlink" href="#aggregating-numeric-data" title="Link to this heading">#</a></h2>
<p>Recall that in the previous chapter we discussed
the <code class="docutils literal notranslate"><span class="pre">heights</span></code> and <code class="docutils literal notranslate"><span class="pre">income</span></code> datasets whose histograms
we gave in <a class="reference internal" href="210-vector.html#fig-heights-histogram-bins11"><span class="std std-numref">Figure 4.2</span></a>
and <a class="reference internal" href="210-vector.html#fig-income-histogram-bins20"><span class="std std-numref">Figure 4.3</span></a>, respectively.
Such graphical summaries are based on binned data. They
provide us with snapshots of how much probability mass
is allocated in different parts of the data domain.</p>
<p>Instead of dealing with large datasets, we obtained a few counts.
The process of binning and its textual or visual depictions
is valuable in determining whether the distribution
is unimodal or multimodal, skewed or symmetric around
some point, what range of values contains most of the observations,
and how small or large extreme values are.</p>
<div style="margin-top: 1em"></div><p>Too much information may sometimes be overwhelming. Besides,
revealing it might not be a clever idea for privacy or confidentiality
reasons<a class="footnote-reference brackets" href="#footprivacy" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.
Consequently, we might be interested in even more synthetic descriptions –
data aggregates which reduce the whole dataset into a <em>single</em>
number reflecting one of its many characteristics.
They can provide us with a kind of bird’s-eye view of some of its aspects.
We refer to such processes as data <em>aggregation</em>;
see <span id="id3">[<a class="reference internal" href="999-bibliography.html#id15" title="Gagolewski, M. (2015).  Data Fusion: Theory, Methods, and Applications. Institute of Computer Science, Polish Academy of Sciences. DOI: 10.5281/zenodo.6960306.">30</a>, <a class="reference internal" href="999-bibliography.html#id16" title="Grabisch, M., Marichal, J.-L., Mesiar, R., and Pap, E. (2009).  Aggregation Functions. Cambridge University Press.">43</a>]</span>.</p>
<div style="margin-top: 1em"></div><p>In this part, we discuss a few noteworthy <em>measures</em> of:</p>
<ul class="simple">
<li><p><em>location</em>; e.g., central tendency measures such as mean and median;</p></li>
<li><p><em>dispersion</em>; e.g., standard deviation and interquartile range;</p></li>
<li><p>distribution <em>shape</em>; e.g., skewness.</p></li>
</ul>
<p>We also introduce <em>box-and-whisker plots</em>.</p>
<section id="measures-of-location">
<h3><span class="section-number">5.1.1. </span>Measures of location<a class="headerlink" href="#measures-of-location" title="Link to this heading">#</a></h3>
<section id="arithmetic-mean-and-median">
<h4><span class="section-number">5.1.1.1. </span>Arithmetic mean and median<a class="headerlink" href="#arithmetic-mean-and-median" title="Link to this heading">#</a></h4>
<p>Two main measures of <em>central tendency</em> are:</p>
<ul>
<li><p><em>the arithmetic mean</em> (sometimes for simplicity called the mean or average),
defined as the sum of all observations divided by the sample size:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
    \bar{x} = \frac{(x_1+x_2+\dots+x_n)}{n} = \frac{1}{n} \sum_{i=1}^n x_i,
    \]</div>
</div>
</li>
<li><p><em>the median</em>, being the middle value in a sorted version of the
sample if its length is odd
or the arithmetic mean of the two middle values otherwise:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
    m = \left\{
    \begin{array}{ll}
    x_{((n+1)/2)} & \text{if }n\text{ is odd},\\
    \frac{x_{(n/2)}+x_{(n/2+1)}}{2} & \text{if }n\text{ is even}.
    \end{array}
    \right.
    \]</div>
</div>
</li>
</ul>
<p>They can be computed using the <strong class="command">numpy.mean</strong> and
<strong class="command">numpy.median</strong> functions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">heights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/gagolews/&quot;</span> <span class="o">+</span>
    <span class="s2">&quot;teaching-data/master/marek/nhanes_adult_female_height_2020.txt&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">heights</span><span class="p">)</span>
<span class="c1">## (160.13679222932953, 160.1)</span>
<span class="n">income</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/gagolews/&quot;</span> <span class="o">+</span>
    <span class="s2">&quot;teaching-data/master/marek/uk_income_simulated_2020.txt&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">income</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">income</span><span class="p">)</span>
<span class="c1">## (35779.994, 30042.0)</span>
</pre></div>
</div>
<p>Let us underline what follows:</p>
<ul class="simple">
<li><p>for symmetric distributions,
the arithmetic mean and the median are
expected to be more or less equal,</p></li>
<li><p>for skewed distributions, the arithmetic mean will be biased towards
the heavier tail.</p></li>
</ul>
<div class="proof proof-type-exercise" id="id21">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.1</span>
        
    </div><div class="proof-content">
<p>Get the arithmetic mean
and median for the <code class="docutils literal notranslate"><span class="pre">37_pzu_warsaw_marathon_mins</span></code> dataset
mentioned in <a class="reference internal" href="210-vector.html#chap-vector"><span class="std std-numref">Chapter 4</span></a>.</p>
</div></div><div class="proof proof-type-exercise" id="id22">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.2</span>
        
    </div><div class="proof-content">
<p>(*) Write a function
that computes the median without the use of <strong class="command">numpy.median</strong>
(based on its mathematical definition and <strong class="command">numpy.sort</strong>).</p>
</div></div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>(*) Technically, the arithmetic mean can also be computed
using the <strong class="command">mean</strong> <em>method</em> for the <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> class.
It will sometimes be the case that we have many ways to perform the same
operation. We can even compose it manually using
the <strong class="command">sum</strong> function. Thus, all the following expressions are
equivalent:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">income</span><span class="p">),</span>
    <span class="n">income</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">income</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">income</span><span class="p">),</span>
    <span class="n">income</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">income</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="p">)</span>
<span class="c1">## 35779.994 35779.994 35779.994 35779.994</span>
</pre></div>
</div>
<p>On the other hand, there exists the <strong class="command">numpy.median</strong> function
but, unfortunately, the <strong class="command">median</strong> method for vectors is not
available. This is why we prefer sticking with functions.</p>
</div>
</section>
<section id="sensitive-to-outliers-vs-robust">
<span id="sec-robust-intro-median"></span><h4><span class="section-number">5.1.1.2. </span>Sensitive to outliers vs robust<a class="headerlink" href="#sensitive-to-outliers-vs-robust" title="Link to this heading">#</a></h4>
<p>The arithmetic mean is strongly influenced by very large
or very small observations (which in some contexts we refer
to as <em>outliers</em>). For instance, assume that we are inviting
a billionaire to the <code class="docutils literal notranslate"><span class="pre">income</span></code> dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">income2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">income</span><span class="p">,</span> <span class="p">[</span><span class="mi">1_000_000_000</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">income</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">income2</span><span class="p">))</span>
<span class="c1">## 35779.994 1034745.2487512487</span>
</pre></div>
</div>
<p>Comparing this new result to the previous one,
oh we all feel much richer now, right?
In fact, the arithmetic mean reflects the income each of us would
get if all the wealth were gathered inside a single Santa Claus’s (or Robin Hood’s) sack and then distributed equally amongst all of us.
A noble idea provided that everyone contributes equally
to the society, which unfortunately is not the case.</p>
<div style="margin-top: 1em"></div><p>On the other hand, the median is the value
such that 50% of the observations are less than or equal to it
and 50% of the remaining ones are not less than it.
Hence, it is completely insensitive to most of the data points
on both the left and the right side of the distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">income</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">income2</span><span class="p">))</span>
<span class="c1">## 30042.0 30076.0</span>
</pre></div>
</div>
<div style="margin-top: 1em"></div><p>We cannot thus say that one measure is better than the other.
Certainly, for symmetrical distributions with no outliers (e.g., <code class="docutils literal notranslate"><span class="pre">heights</span></code>),
the mean will be better as it uses <em>all</em> data (and its efficiency
can be proven for certain statistical models).
For skewed distributions (e.g., <code class="docutils literal notranslate"><span class="pre">income</span></code>),
the median has a nice interpretation, as it gives the value in the middle
of the ordered sample. Let us still remember that these data
summaries allow us to look at a single data aspect only,
and there can be many different, valid perspectives.
The reality is complex.</p>
</section>
<section id="sample-quantiles">
<span id="sec-quantiles"></span><h4><span class="section-number">5.1.1.3. </span>Sample quantiles<a class="headerlink" href="#sample-quantiles" title="Link to this heading">#</a></h4>
<p>Quantiles generalise the notions of the sample median and of the inverse
of the empirical cumulative distribution function (<a class="reference internal" href="210-vector.html#sec-ecdf"><span class="std std-numref">Section 4.3.8</span></a>).
They provide us with the value that is not exceeded by the elements
in a given sample with a predefined probability.</p>
<p>Before proceeding with a formal definition, which is quite technical,
let us point out that for larger sample sizes, we have the
following rule of thumb.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>For any <span class="math">\(p\)</span> between 0 and 1, the <span class="math">\(p\)</span>-quantile,
denoted <span class="math">\(q_p\)</span>, is a value dividing the sample in such a way that
approximately <span class="math">\(100p\%\)</span> of observations are not greater than <span class="math">\(q_p\)</span>,
and the remaining circa <span class="math">\(100(1-p)\%\)</span> are not less than <span class="math">\(q_p\)</span>.</p>
</div>
<p>Quantiles appear under many different names, but they
all refer to the same concept.
In particular, we can speak about the <span class="math">\(100p\)</span>-th <em>percentiles</em>,
e.g., the 0.5-quantile is the same as the 50th percentile.</p>
<p>Furthermore:</p>
<ul class="simple">
<li><p>0-quantile (<span class="math">\(q_0\)</span>)       – the minimum (also: <strong class="command">numpy.min</strong>),</p></li>
<li><p>0.25-quantile (<span class="math">\(q_{0.25}\)</span>) – the first quartile (denoted <span class="math">\(Q_1\)</span>),</p></li>
<li><p>0.5-quantile (<span class="math">\(q_{0.5}\)</span>)  – the second quartile a.k.a. median
(denoted <span class="math">\(m\)</span> or <span class="math">\(Q_2\)</span>),</p></li>
<li><p>0.75-quantile (<span class="math">\(q_{0.75}\)</span>) – the third quartile (denoted <span class="math">\(Q_3\)</span>),</p></li>
<li><p>1.0-quantile (<span class="math">\(q_{1}\)</span>)   – the maximum (also: <strong class="command">numpy.max</strong>).</p></li>
</ul>
<p>Here are the above five aggregates for our two datasets:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="c1">## array([131.1, 155.3, 160.1, 164.8, 189.3])</span>
<span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">income</span><span class="p">,</span>  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="c1">## array([  5750.  ,  20669.75,  30042.  ,  44123.75, 199969.  ])</span>
</pre></div>
</div>
<div class="proof proof-type-example" id="id23">

    <div class="proof-title">
        <span class="proof-type">Example 5.3</span>
        
    </div><div class="proof-content">
<p>The same as above, but now printed neatly using f-strings;
see <a class="reference internal" href="120-scalar.html#sec-f-strings"><span class="std std-numref">Section 2.1.3.1</span></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wh</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">qheights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="n">wh</span><span class="p">)</span>
<span class="n">qincome</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">income</span><span class="p">,</span> <span class="n">wh</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;          heights     income&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wh</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;q_</span><span class="si">{</span><span class="n">wh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;4g</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">qheights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">10.2f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">qincome</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">10.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1">##           heights     income</span>
<span class="c1">## q_0        131.10    5750.00</span>
<span class="c1">## q_0.25     155.30   20669.75</span>
<span class="c1">## q_0.5      160.10   30042.00</span>
<span class="c1">## q_0.75     164.80   44123.75</span>
<span class="c1">## q_1        189.30  199969.00</span>
</pre></div>
</div>
</div></div><div class="proof proof-type-exercise" id="id24">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.4</span>
        
    </div><div class="proof-content">
<p>What is the income bracket for 95% of the <em>most typical</em> UK
taxpayers? In other words, determine the 2.5- and 97.5-percentiles.</p>
</div></div><div class="proof proof-type-exercise" id="id25">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.5</span>
        
    </div><div class="proof-content">
<p>Compute the <em>midrange</em> of <code class="docutils literal notranslate"><span class="pre">income</span></code> and <code class="docutils literal notranslate"><span class="pre">heights</span></code>,
being the arithmetic mean of the minimum and the maximum
(this measure is extremely sensitive to outliers).</p>
</div></div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>(*)
As we do not like the <em>approximately</em> part in the
“asymptotic definition” given above, in this course
we shall assume that for any <span class="math">\(p\in[0, 1]\)</span>, the <span class="math">\(p\)</span>-quantile is given by</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
    q_p =
    x_{(\lfloor k\rfloor)} +
    (k-\lfloor k\rfloor) (x_{(\lfloor k\rfloor+1)}-x_{(\lfloor k\rfloor)}),
\]</div>
</div>
<p>where <span class="math">\(k=(n-1)p+1\)</span>
and <span class="math">\(\lfloor k\rfloor\)</span> is the floor function, i.e.,
the greatest integer less than or equal to <span class="math">\(k\)</span> (e.g.,
<span class="math">\(\lfloor 2.0\rfloor=\lfloor 2.001\rfloor=\lfloor 2.999\rfloor=2\)</span>,
<span class="math">\(\lfloor 3.0\rfloor=\lfloor 3.999\rfloor=3\)</span>,
<span class="math">\(\lfloor -3.0\rfloor=\lfloor -2.999\rfloor=\lfloor -2.001\rfloor=-3\)</span>, and
<span class="math">\(\lfloor -2.0\rfloor=\lfloor -1.001\rfloor=-2\)</span>).</p>
<p><span class="math">\(q_p\)</span> is a function that linearly interpolates between
the points featuring the consecutive order statistics,
<span class="math">\(((k - 1) / (n - 1), x_{(k)})\)</span> for <span class="math">\(k=1,\dots,n\)</span>.
For instance, for <span class="math">\(n=5\)</span>, we connect the points
<span class="math">\((0, x_{(1)})\)</span>, <span class="math">\((0.25, x_{(2)})\)</span>, <span class="math">\((0.5, x_{(3)})\)</span>,
<span class="math">\((0.75, x_{(4)})\)</span>, <span class="math">\((1, x_{(5)})\)</span>.
For <span class="math">\(n=6\)</span>, we do the same for
<span class="math">\((0, x_{(1)})\)</span>, <span class="math">\((0.2, x_{(2)})\)</span>, <span class="math">\((0.4, x_{(3)})\)</span>,
<span class="math">\((0.6, x_{(4)})\)</span>, <span class="math">\((0.8, x_{(5)})\)</span>, <span class="math">\((1, x_{(6)})\)</span>;
see <a class="reference internal" href="#fig-quantile7"><span class="std std-numref">Figure 5.1</span></a>.</p>
<p>Notice that for <span class="math">\(p=0.5\)</span> we get the median regardless
of whether <span class="math">\(n\)</span> is even or not.</p>
</div>
<figure class="align-default" id="id26">
<span id="fig-quantile7"></span><img alt="../_images/quantile7-1.png" src="../_images/quantile7-1.png" />
<figcaption>
<p><span class="caption-number">Figure 5.1 </span><span class="caption-text"><span class="math">\(q_p\)</span> as a function of <span class="math">\(p\)</span> for example vectors of length 5 (left subfigure) and 6 (right).</span><a class="headerlink" href="#id26" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>(**) There are many definitions
of quantiles across statistical software; see
the <code class="docutils literal notranslate"><span class="pre">method</span></code> argument to <strong class="command">numpy.quantile</strong>.
They were nicely summarised in <span id="id4">[<a class="reference internal" href="999-bibliography.html#id12" title="Hyndman, R.J. and Fan, Y. (1996).  Sample quantiles in statistical packages. American Statistician, 50(4):361–365. DOI: 10.2307/2684934.">53</a>]</span>
as well as in the corresponding <a class="reference external" href="https://en.wikipedia.org/wiki/Quantile">Wikipedia</a> article.
They are all approximately equivalent for large sample sizes
(i.e., asymptotically), but the best practice is to be explicit about
which variant we are using in the computations when reporting
data analysis results.
Accordingly, in our case, we say that we are relying on
the type-7 quantiles as described in <span id="id5">[<a class="reference internal" href="999-bibliography.html#id12" title="Hyndman, R.J. and Fan, Y. (1996).  Sample quantiles in statistical packages. American Statistician, 50(4):361–365. DOI: 10.2307/2684934.">53</a>]</span>;
see also <span id="id6">[<a class="reference internal" href="999-bibliography.html#id41" title="Gumbel, E.J. (1939).  La probabilité des hypothèses. Comptes Rendus de l'Académie des Sciences Paris, 209:645–647.">44</a>]</span>.</p>
<p>In fact, simply mentioning that our computations are done with
<strong class="command">numpy</strong> version 1.xx (as specified in <a class="reference internal" href="110-setup.html#sec-init"><span class="std std-numref">Section 1.4</span></a>)
implicitly implies that the default method parameters are used everywhere,
unless otherwise stated.
In many contexts, that is good enough.</p>
</div>
</section>
</section>
<section id="measures-of-dispersion">
<h3><span class="section-number">5.1.2. </span>Measures of dispersion<a class="headerlink" href="#measures-of-dispersion" title="Link to this heading">#</a></h3>
<p>Measures of central tendency quantify the location of the
most <em>typical</em> value (whatever that means, and we already
know it is complicated). That of dispersion (spread), on the other hand,
will tell us how much <em>variability</em> is in our data.
After all, when we say that the height of a group of people is 160 cm
(on average) ± 14 cm (here, 2 standard deviations), the latter
piece of information is a valuable addition
(and is very different from the imaginary ± 4 cm case).</p>
<p>Some degree of variability might be welcome in certain contexts and
disastrous in others. A bolt factory should keep the variance of the
fasteners’ diameters as low as possible: this is how we define quality
products (assuming that they all meet, on average, the required
specification). Nevertheless, too much diversity in human behaviour,
where everyone feels that they are special, is not really sustainable
(but lack thereof would be extremely boring).</p>
<p>Let us explore the different ways in which we can quantify
this data aspect.</p>
<section id="standard-deviation-and-variance">
<h4><span class="section-number">5.1.2.1. </span>Standard deviation (and variance)<a class="headerlink" href="#standard-deviation-and-variance" title="Link to this heading">#</a></h4>
<p>The standard deviation<a class="footnote-reference brackets" href="#footsdbiased" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>,
is the average distance to the arithmetic mean:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
s = \sqrt{
\frac{ (x_1-\bar{x})^2 + (x_2-\bar{x})^2 + \dots + (x_n-\bar{x})^2 }{n}
}
=
\sqrt{
\frac{1}{n} \sum_{i=1}^n (x_i-\bar{x})^2.
}
\]</div>
</div>
<p>Computing the above with <strong class="program">numpy</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">heights</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">income</span><span class="p">)</span>
<span class="c1">## (7.062021850008261, 22888.77122437908)</span>
</pre></div>
</div>
<p>The standard deviation quantifies the typical amount of spread around the
arithmetic mean.
It is overall adequate for making comparisons across different samples
measuring similar things (e.g., heights of males vs of females,
incomes in the UK vs in South Africa).
However, without further assumptions, it is quite difficult to express the
meaning of a particular value of <span class="math">\(s\)</span> (e.g., the statement
that the standard deviation of income is £22 900 is hard to interpret).
This measure makes therefore most sense for data distributions that
are symmetric around the mean.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>(*)
For bell-shaped data such as <code class="docutils literal notranslate"><span class="pre">heights</span></code> (more precisely:
for normally-distributed samples; see the next chapter),
we sometimes report <span class="math">\(\bar{x}\pm 2s\)</span>. By the so-called <span class="math">\(2\sigma\)</span> rule,
the theoretical expectancy is that roughly 95% of data points
fall into the <span class="math">\([\bar{x}-2s, \bar{x}+2s]\)</span> interval.</p>
</div>
<p>Further, the <em>variance</em> is the square of the standard deviation, <span class="math">\(s^2\)</span>.
Mind that if data are expressed in centimetres,
then the variance is in centimetres <em>squared</em>, which
is not very intuitive. The standard deviation does not have this
drawback. Mathematicians find the square root annoying though
(for many reasons); that is why we will come across the <span class="math">\(s^2\)</span>
every now and then too.</p>
</section>
<section id="interquartile-range">
<h4><span class="section-number">5.1.2.2. </span>Interquartile range<a class="headerlink" href="#interquartile-range" title="Link to this heading">#</a></h4>
<p>The interquartile range (IQR) is another popular measure of dispersion.
It is defined as the difference between the third
and the first quartile:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
\mathrm{IQR} = q_{0.75}-q_{0.25} = Q_3-Q_1.
\]</div>
</div>
<p>Computing the above is almost effortless:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>
<span class="c1">## 9.5</span>
<span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">income</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">income</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>
<span class="c1">## 23454.0</span>
</pre></div>
</div>
<p>The IQR has an appealing interpretation:
it is the range comprised of the 50% <em>most typical</em>
values. It is a quite robust measure, as it ignores the 25% smallest
and 25% largest observations.
Standard deviation, on the other hand, is extremely sensitive to outliers.</p>
<p>Furthermore, by <em>range</em> (or support) we will mean a measure based on
extremal quantiles: it is the difference between the maximal
and minimal observation.</p>
</section>
</section>
<section id="measures-of-shape">
<h3><span class="section-number">5.1.3. </span>Measures of shape<a class="headerlink" href="#measures-of-shape" title="Link to this heading">#</a></h3>
<p>From a histogram, we can easily read whether a dataset is
symmetric or skewed. It turns out that we can easily quantify
such a characteristic. Namely, the <em>skewness</em> is given by:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
g = \frac{
\frac{1}{n}\sum_{i=1}^n (x_i-\bar{x})^3
}{
\left(\sqrt{\frac{1}{n}\sum_{i=1}^n (x_i-\bar{x})^2}\right)^3
}.
\]</div>
</div>
<p>For symmetric distributions, skewness is approximately zero.
Positive and negative skewness indicates a heavier right
and left tail, respectively.</p>
<p>For example, heights are an instance of an almost-symmetric distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">heights</span><span class="p">)</span>
<span class="c1">## 0.0811184528074054</span>
</pre></div>
</div>
<p>Income, on the other hand, is right-skewed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">income</span><span class="p">)</span>
<span class="c1">## 1.9768735693998942</span>
</pre></div>
</div>
<p>Now we have them expressed as a single number.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>(*)
It is worth stressing that <span class="math">\(g&gt;0\)</span> does not imply that the sample mean
is greater than the median. As an alternative measure of skewness,
sometimes the practitioners use:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
g'=\frac{\bar{x}-m}{s}.
\]</div>
</div>
<p><em>Yule’s coefficient</em> is an example of a robust
skewness measure:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
g''=\frac{Q_3+Q_1-2m}{Q_3-Q_1}.
\]</div>
</div>
<p>The computation thereof on our example datasets is left as an exercise.</p>
<p>Furthermore, <em>kurtosis</em> (or Fisher’s excess kurtosis,
compare <strong class="command">scipy.stats.kurtosis</strong>) describes whether
an empirical distribution is heavy- or thin-tailed.</p>
</div>
</section>
<section id="box-and-whisker-plots">
<span id="sec-boxplot"></span><h3><span class="section-number">5.1.4. </span>Box (and whisker) plots<a class="headerlink" href="#box-and-whisker-plots" title="Link to this heading">#</a></h3>
<p>A <em>box-and-whisker</em> plot (<em>box plot</em> for short)
depicts some noteworthy features of a data sample.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># two rows, one column; the first subplot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;heights&quot;</span><span class="p">])</span>  <span class="c1"># label at y=1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># two rows, one column; the second subplot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">income</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;income&quot;</span><span class="p">])</span>  <span class="c1"># label at y=1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id27">
<span id="fig-boxplot-income-heights"></span><img alt="../_images/boxplot-income-heights-3.png" src="../_images/boxplot-income-heights-3.png" />
<figcaption>
<p><span class="caption-number">Figure 5.2 </span><span class="caption-text">Example box plots.</span><a class="headerlink" href="#id27" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Each box plot (compare <a class="reference internal" href="#fig-boxplot-income-heights"><span class="std std-numref">Figure 5.2</span></a>)
consists of:</p>
<ul class="simple">
<li><p>the box, which spans between the first and the third quartile:</p>
<ul>
<li><p>the median is clearly marked by a vertical bar inside the box;</p></li>
<li><p>the width of the box corresponds to the IQR;</p></li>
</ul>
</li>
<li><p>the whiskers, which span<a class="footnote-reference brackets" href="#footiqr15" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> between:</p>
<ul>
<li><p>the smallest observation (the minimum)
or <span class="math">\(Q_1-1.5 \mathrm{IQR}\)</span> (the left side of the box minus
3/2 of its width), whichever is larger, and</p></li>
<li><p>the largest observation (the maximum)
or <span class="math">\(Q_3+1.5 \mathrm{IQR}\)</span> (the right side of the box
plus 3/2 of its width), whichever is smaller.</p></li>
</ul>
</li>
</ul>
<p>Additionally, all observations that are less than
<span class="math">\(Q_1-1.5 \mathrm{IQR}\)</span> (if any)
or greater than <span class="math">\(Q_3+1.5 \mathrm{IQR}\)</span> (if any)
are separately marked.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We are used to referring to the individually marked points
as <em>outliers</em>. Still, it does not automatically mean there is anything
<em>anomalous</em> about them.
They are <em>atypical</em> in the sense that they are
considerably farther away from the box.
But this might as well indicate some problems in data quality
(e.g., when someone made a typo entering the data).
Actually, box plots are calibrated
(via the nicely round magic constant 1.5)
in such a way that we expect there
to be no or only few outliers if the data are normally distributed.
For skewed distributions, there will naturally be many outliers
on either side; see <a class="reference internal" href="520-missingness.html#sec-outliers"><span class="std std-numref">Section 15.4</span></a> for more details.</p>
</div>
<p>Box plots are based solely on sample quantiles.
Most of the statistical packages <em>do not</em> draw the arithmetic mean.
If they do, it is marked with a distinctive symbol.</p>
<div class="proof proof-type-exercise" id="id28">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.6</span>
        
    </div><div class="proof-content">
<p>Call
<strong class="command">matplotlib.pyplot.plot</strong><code class="code docutils literal notranslate"><span class="pre">(</span></code><strong class="command">numpy.mean</strong><code class="code docutils literal notranslate"><span class="pre">(..data..),</span> <span class="pre">0,</span> <span class="pre">&quot;bX&quot;)</span></code> to mark the arithmetic mean with a blue cross.
Alternatively, pass <code class="docutils literal notranslate"><span class="pre">showmeans=True</span></code> (amongst others)
to <strong class="command">matplotlib.pyplot.boxplot</strong>.</p>
</div></div><p>Box plots are particularly beneficial for comparing data samples with each
other (e.g., body measures of men and women separately),
both in terms of the relative shift (location)
as well as spread and skewness; see, e.g., <a class="reference internal" href="430-group-by.html#fig-gender-usborn-bmi"><span class="std std-numref">Figure 12.1</span></a>.</p>
<div class="proof proof-type-example" id="id29">

    <div class="proof-title">
        <span class="proof-type">Example 5.7</span>
        
    </div><div class="proof-content">
<p>(*)
We may also be interested in a <em>violin plot</em>
(<a class="reference internal" href="#fig-violinplot-income"><span class="std std-numref">Figure 5.3</span></a>). Its shape is based on a kernel density
estimator, which is a smoothened version of a histogram;
see <a class="reference internal" href="520-missingness.html#sec-kde-1d"><span class="std std-numref">Section 15.4.2</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># two rows, one column; the first subplot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">showextrema</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;heights&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># two rows, one column; the second subplot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">income</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">showextrema</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">income</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;income&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id30">
<span id="fig-violinplot-income"></span><img alt="../_images/violinplot-income-5.png" src="../_images/violinplot-income-5.png" />
<figcaption>
<p><span class="caption-number">Figure 5.3 </span><span class="caption-text">Example violin plots.</span><a class="headerlink" href="#id30" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div></div></section>
<section id="further-methods">
<h3><span class="section-number">5.1.5. </span>Further methods (*)<a class="headerlink" href="#further-methods" title="Link to this heading">#</a></h3>
<p>We said that the arithmetic mean is overly sensitive to extreme observations.
The sample median is an example of a <em>robust</em> aggregate — it ignores
all but 1–2 middle observations (we would say it has
a high <em>breakdown point</em>). Some measures of central tendency
that are in-between the mean-median extreme include:</p>
<ul class="simple">
<li><p><em>trimmed means</em> – the arithmetic mean of all the observations except
several, say <span class="math">\(p\)</span>, the smallest and the greatest ones,</p></li>
<li><p><em>winsorised means</em> – the arithmetic mean with <span class="math">\(p\)</span> smallest and <span class="math">\(p\)</span> greatest
observations replaced with the <span class="math">\((p+1)\)</span>-th smallest
the <span class="math">\((p+1)\)</span>-th largest one.</p></li>
</ul>
<p>The arithmetic mean is not the only mean of interest.
The two other famous means are the <em>geometric</em> and <em>harmonic</em> ones.
The former is more meaningful for averaging growth rates and speedups
whilst the latter can be used for computing the average speed from
speed measurements at sections of identical lengths; see also
the notion of the F measure in <a class="reference internal" href="430-group-by.html#sec-classifier-metrics"><span class="std std-numref">Section 12.3.2</span></a>.
Also, the quadratic mean is featured in the definition
of the standard deviation (it is the quadratic mean of the
distances to the mean).</p>
<div style="margin-top: 1em"></div><p>As far as spread measures are concerned, the interquartile range (IQR)
is a robust statistic.
If necessary, the standard deviation might be replaced with:</p>
<ul class="simple">
<li><p>mean absolute deviation from the mean:
<span class="math">\(\frac{1}{n} \sum_{i=1}^n |x_i-\bar{x}|\)</span>,</p></li>
<li><p>mean absolute deviation from the median:
<span class="math">\(\frac{1}{n} \sum_{i=1}^n |x_i-m|\)</span>,</p></li>
<li><p>median absolute deviation from the median:
the median of <span class="math">\((|x_1-m|, |x_2-m|, \dots, |x_n-m|)\)</span>.</p></li>
</ul>
<p>The <em>coefficient of variation</em>, being the standard deviation
divided by the arithmetic mean, is an example of a <em>relative</em> (or
normalised) spread measure. It can be appropriate for comparing data
on different scales, as it is unitless
(think how standard deviation changes when you
convert between metres and centimetres).</p>
<p>The <em>Gini index</em>,
widely used in economics, can also serve as a measure of relative
dispersion, but assumes that all data points are nonnegative:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
G = \frac{
\sum_{i=1}^{n} \sum_{j=1}^n |x_i-x_j|
}{
2 (n-1)n\, \bar{x}
}
=
\frac{
\sum_{i=1}^{n} (n-2i+1) x_{(n-i+1)}
}{
(n-1) \sum_{i=1}^n x_i
}.
\]</div>
</div>
<p>It is normalised so that it takes values in the unit interval.
An index of 0 reflects the situation where all values in a sample are the
same (0 variance; perfect equality).
If there is a single entity in possession of all the “wealth”,
and the remaining ones are 0, then the index is equal to 1.</p>
<div style="margin-top: 1em"></div><p>For a more generic (algebraic) treatment of aggregation functions
for unidimensional data; see, e.g., <span id="id9">[<a class="reference internal" href="999-bibliography.html#id119" title="Bullen, P.S. (2003).  Handbook of Means and Their Inequalities. Springer Science+Business Media.">11</a>, <a class="reference internal" href="999-bibliography.html#id15" title="Gagolewski, M. (2015).  Data Fusion: Theory, Methods, and Applications. Institute of Computer Science, Polish Academy of Sciences. DOI: 10.5281/zenodo.6960306.">30</a>, <a class="reference internal" href="999-bibliography.html#id14" title="Gagolewski, M. (2015).  Spread measures and their relation to aggregation functions. European Journal of Operational Research, 241(2):469–477. DOI: 10.1016/j.ejor.2014.08.034.">31</a>, <a class="reference internal" href="999-bibliography.html#id16" title="Grabisch, M., Marichal, J.-L., Mesiar, R., and Pap, E. (2009).  Aggregation Functions. Cambridge University Press.">43</a>]</span>.
Some measures might be better than others under certain
(often strict) assumptions usually explored in a
course on mathematical statistics, e.g., <span id="id10">[<a class="reference internal" href="999-bibliography.html#id45" title="Gentle, J.E. (2020).  Theory of Statistics. book draft. URL: https://mason.gmu.edu/~jgentle/books/MathStat.pdf.">40</a>]</span>.</p>
<p>Overall, numerical aggregates can be used in cases where
data are unimodal. For multimodal mixtures or data in groups,
they should rather be applied to summarise each cluster/class separately;
compare <a class="reference internal" href="430-group-by.html#chap-group-by"><span class="std std-numref">Chapter 12</span></a>.
Also, <a class="reference internal" href="320-transform-matrix.html#chap-transform-matrix"><span class="std std-numref">Chapter 8</span></a> will extend some
of the summaries for the case of multidimensional data.</p>
</section>
</section>
<section id="vectorised-mathematical-functions">
<span id="sec-vecfun"></span><h2><span class="section-number">5.2. </span>Vectorised mathematical functions<a class="headerlink" href="#vectorised-mathematical-functions" title="Link to this heading">#</a></h2>
<p><strong class="program">numpy</strong>, just like any other comprehensive numerical computing
package, library, or environment (e.g., R, GNU Octave, Scilab, and Julia),
defines many basic mathematical functions:</p>
<ul class="simple">
<li><p>absolute value: <strong class="command">numpy.abs</strong>,</p></li>
<li><p>square and square root: <strong class="command">numpy.square</strong>
and <strong class="command">numpy.sqrt</strong>, respectively,</p></li>
<li><p>(natural) exponential function: <strong class="command">numpy.exp</strong>,</p></li>
<li><p>logarithms: <strong class="command">numpy.log</strong> (the natural logarithm, i.e., base <span class="math">\(e\)</span>),
<strong class="command">numpy.log10</strong> (base <span class="math">\(10\)</span>), etc.,</p></li>
<li><p>trigonometric functions: <strong class="command">numpy.cos</strong>, <strong class="command">numpy.sin</strong>,
<strong class="command">numpy.tan</strong>, etc.,
and their inverses: <strong class="command">numpy.arccos</strong>, etc.</p></li>
<li><p>rounding and truncating: <strong class="command">numpy.round</strong>, <strong class="command">numpy.floor</strong>,
<strong class="command">numpy.ceil</strong>, <strong class="command">numpy.trunc</strong>.</p></li>
</ul>
<p>Each of these functions is <em>vectorised</em>. Applying, say, <span class="math">\(f\)</span>,
on a vector like <span class="math">\(\boldsymbol{x}=(x_1,\dots,x_n)\)</span>, we
obtain a sequence of the same size
with all elements appropriately transformed:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
f(\boldsymbol{x}) = (f(x_1), f(x_2), \dots, f(x_n)).
\]</div>
</div>
<p>In other words, <span class="math">\(f\)</span> operates element by element on the whole array.</p>
<p>Vectorised operations are frequently used for making
adjustments to data,
e.g., as in <a class="reference internal" href="230-distribution.html#fig-heights-lognormal"><span class="std std-numref">Figure 6.8</span></a>, where
we discover that the <em>logarithm</em> of the UK incomes
has a bell-shaped distribution.</p>
<div style="margin-top: 1em"></div><p>An example call to the vectorised version of the rounding function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">([</span><span class="o">-</span><span class="mf">3.249</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.151</span><span class="p">,</span> <span class="mf">2.49</span><span class="p">,</span> <span class="mf">2.51</span><span class="p">,</span> <span class="mf">3.49</span><span class="p">,</span> <span class="mf">3.51</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">## array([-3.2, -3.2,  2.5,  2.5,  3.5,  3.5])</span>
</pre></div>
</div>
<p>The input list has been automatically converted
to a <strong class="program">numpy</strong> vector.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Thanks to the vectorised functions, our code is not only more
readable, but also runs faster: we do not have to employ
the generally slow Python-level <strong class="command">while</strong> or <strong class="command">for</strong> loops
to traverse through each element in a given sequence.</p>
</div>
<section id="logarithms-and-exponential-functions">
<h3><span class="section-number">5.2.1. </span>Logarithms and exponential functions<a class="headerlink" href="#logarithms-and-exponential-functions" title="Link to this heading">#</a></h3>
<p>Here are some significant properties of the natural logarithm
and its inverse, the exponential function.
By convention, Euler’s number <span class="math">\(e \simeq 2.718\)</span>,
<span class="math">\(\log x = \log_e x\)</span>, and <span class="math">\(\exp(x)=e^x\)</span>.</p>
<ul class="simple">
<li><p><span class="math">\(\log 1 = 0\)</span>, <span class="math">\(\log e = 1\)</span>; note that logarithms are
only defined for <span class="math">\(x &gt; 0\)</span>: in the limit as <span class="math">\(x \to 0\)</span>,
we have that <span class="math">\(\log x \to -\infty\)</span>,</p></li>
<li><p><span class="math">\(\log x^y = y \log x\)</span> and hence <span class="math">\(\log e^x = x\)</span>,</p></li>
<li><p><span class="math">\(\log (xy) = \log x + \log y\)</span> and thus <span class="math">\(\log (x/y) = \log x - \log y\)</span>,</p></li>
<li><p><span class="math">\(e^0 = 1\)</span>, <span class="math">\(e^1=e\)</span>, and <span class="math">\(e^x\to 0\)</span> as <span class="math">\(x \to -\infty\)</span>,</p></li>
<li><p><span class="math">\(e^{\log x} = x\)</span>,</p></li>
<li><p><span class="math">\(e^{x+y} = e^x e^y\)</span> and so <span class="math">\(e^{x-y}=e^x / e^y\)</span>,</p></li>
<li><p><span class="math">\(e^{xy} = (e^x)^y\)</span>.</p></li>
</ul>
<p>Both functions are strictly increasing.
For <span class="math">\(x\ge 1\)</span>, the logarithm grows very slowly whereas the exponential
function increases very rapidly; see <a class="reference internal" href="#fig-log-exp"><span class="std std-numref">Figure 5.4</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="mi">1001</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$y=</span><span class="se">\\</span><span class="s2">log x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$y=</span><span class="se">\\</span><span class="s2">exp(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id31">
<span id="fig-log-exp"></span><img alt="../_images/log-exp-7.png" src="../_images/log-exp-7.png" />
<figcaption>
<p><span class="caption-number">Figure 5.4 </span><span class="caption-text">The natural logarithm (left) and the exponential function (right).</span><a class="headerlink" href="#id31" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div style="margin-top: 1em"></div><p>Logarithms of different bases and non-natural exponential functions are
also available. In particular, when drawing plots, we used
the base-10 logarithmic scales on the axes.
It holds <span class="math">\(\log_{10} x = \frac{\log x}{\log 10}\)</span>
and its inverse is <span class="math">\(10^x = e^{x \log 10}\)</span>.
For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mf">10.0</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># see below</span>
<span class="c1">## array([  0.1,   1. ,  10. , 100. ])</span>
<span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">])</span>
<span class="c1">## array([     nan, -2.     , -1.     ,  0.     ,  0.30103,  0.69897,</span>
<span class="c1">##         1.     ,  2.     ,  3.     ,  4.     ])</span>
<span class="c1">## </span>
<span class="c1">## &lt;string&gt;:1: RuntimeWarning: invalid value encountered in log10</span>
</pre></div>
</div>
<p>Take note of the warning and the not-a-number (<code class="docutils literal notranslate"><span class="pre">NaN</span></code>) generated.</p>
<div class="proof proof-type-exercise" id="id32">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.8</span>
        
    </div><div class="proof-content">
<p>Check that when using the log-scale on the x-axis
(<strong class="command">plt.xscale</strong><code class="code docutils literal notranslate"><span class="pre">(&quot;log&quot;)</span></code>), the plot of the logarithm
(of any base) is a straight line. Similarly, the log-scale on the y-axis
(<strong class="command">plt.yscale</strong><code class="code docutils literal notranslate"><span class="pre">(&quot;log&quot;)</span></code>) makes the exponential function
linear.</p>
</div></div></section>
<section id="trigonometric-functions">
<h3><span class="section-number">5.2.2. </span>Trigonometric functions<a class="headerlink" href="#trigonometric-functions" title="Link to this heading">#</a></h3>
<p>Moving on, the trigonometric functions in <strong class="program">numpy</strong>
accept angles in radians.
If <span class="math">\(x\)</span> is the degree in angles, then to compute its
cosine, we should instead write <span class="math">\(\cos (x \pi /180)\)</span>;
see <a class="reference internal" href="#fig-cos"><span class="std std-numref">Figure 5.5</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;$-2</span><span class="se">\\</span><span class="s2">pi$&quot;</span><span class="p">,</span> <span class="s2">&quot;$-</span><span class="se">\\</span><span class="s2">pi$&quot;</span><span class="p">,</span> <span class="s2">&quot;$0$&quot;</span><span class="p">,</span> <span class="s2">&quot;$</span><span class="se">\\</span><span class="s2">pi/2$&quot;</span><span class="p">,</span> <span class="s2">&quot;$</span><span class="se">\\</span><span class="s2">pi$&quot;</span><span class="p">,</span>
     <span class="s2">&quot;$3</span><span class="se">\\</span><span class="s2">pi/2$&quot;</span><span class="p">,</span> <span class="s2">&quot;$2</span><span class="se">\\</span><span class="s2">pi$&quot;</span><span class="p">,</span> <span class="s2">&quot;$4</span><span class="se">\\</span><span class="s2">pi$&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id33">
<span id="fig-cos"></span><img alt="../_images/cos-9.png" src="../_images/cos-9.png" />
<figcaption>
<p><span class="caption-number">Figure 5.5 </span><span class="caption-text">The cosine.</span><a class="headerlink" href="#id33" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Some identities worth memorising:</p>
<ul class="simple">
<li><p><span class="math">\(\sin x = \cos(\pi/2 - x)\)</span>,</p></li>
<li><p><span class="math">\(\cos(-x) = \cos x\)</span>,</p></li>
<li><p><span class="math">\(\cos^2 x + \sin^2 x = 1\)</span>, where <span class="math">\(\cos^2 x = (\cos x)^2\)</span>,</p></li>
<li><p><span class="math">\(\cos(x+y) = \cos x \cos y - \sin x \sin y\)</span>,</p></li>
<li><p><span class="math">\(\cos(x-y) = \cos x \cos y + \sin x \sin y\)</span>.</p></li>
</ul>
<p>We will refer to them later.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The classical handbook of mathematical functions
and the (in)equalities related to them is <span id="id11">[<a class="reference internal" href="999-bibliography.html#id136" title="Abramowitz, M. and Stegun, I.A., editors. (1972).  Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables. Dover Publications. URL: https://personal.math.ubc.ca/~cbm/aands/intro.htm.">1</a>]</span>,
see <span id="id12">[<a class="reference internal" href="999-bibliography.html#id137" title="Olver, F.W.J. and others. (2023).  NIST Digital Library of Mathematical Functions. URL: https://dlmf.nist.gov/.">70</a>]</span> for its updated version.</p>
</div>
</section>
</section>
<section id="arithmetic-operators">
<h2><span class="section-number">5.3. </span>Arithmetic operators<a class="headerlink" href="#arithmetic-operators" title="Link to this heading">#</a></h2>
<p>We can apply the standard binary (two-argument) arithmetic operators
`<strong class="command">+</strong>`, `<strong class="command">-</strong>`, `<strong class="command">*</strong>`,
`<strong class="command">/</strong>`, `<strong class="command">**</strong>`, `<strong class="command">%</strong>`, and
`<strong class="command">//</strong>` on vectors too.
Below we discuss the possible cases of the operands’ lengths.</p>
<section id="vector-scalar-case">
<h3><span class="section-number">5.3.1. </span>Vector-scalar case<a class="headerlink" href="#vector-scalar-case" title="Link to this heading">#</a></h3>
<p>Often, we will be referring to the binary operators
in contexts where one operand is a vector and the other is a single
value (scalar). For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
<span class="c1">## array([4, 1, 0, 1, 4, 9])</span>
<span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span>
<span class="c1">## array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])</span>
</pre></div>
</div>
<p>In such a case, each element in the vector is being
operated upon (e.g., squared, divided by 5)
and we get a vector of the same length in return.
Hence, in this case, the operators behave just like the vectorised
mathematical functions discussed above.</p>
<p>Mathematically, it is common to assume that
the scalar multiplication and, less commonly, the addition
are performed in this way.</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
c \boldsymbol{x} + t = (cx_1+t, cx_2+t, \dots, cx_n+t).
\]</div>
</div>
<p>We will also become used to writing <span class="math">\((\boldsymbol{x}-t)/c\)</span>,
which is equivalent to <span class="math">\((1/c) \boldsymbol{x} + (-t/c)\)</span>.</p>
</section>
<section id="application-feature-scaling">
<span id="sec-standardisation"></span><h3><span class="section-number">5.3.2. </span>Application: Feature scaling<a class="headerlink" href="#application-feature-scaling" title="Link to this heading">#</a></h3>
<p>Vector-scalar operations and aggregation functions are the basis
for the most commonly applied <em>feature scalers</em>:</p>
<ul class="simple">
<li><p>standardisation,</p></li>
<li><p>normalisation,</p></li>
<li><p>min-max scaling and clipping.</p></li>
</ul>
<p>They can increase the interpretability of data points by
bringing them onto a common, unitless scale.
They might also be essential when computing
pairwise distances between multidimensional points; see
<a class="reference internal" href="320-transform-matrix.html#sec-distances"><span class="std std-numref">Section 8.4</span></a>.</p>
<p>The transformations listed above are <em>linear</em>, i.e., of the form
<span class="math">\(\boldsymbol{y}=c \boldsymbol{x}+t\)</span>.
We can interpret them geometrically as scaling
(stretching or shrinking) and shifting (translating);
see <a class="reference internal" href="#fig-scale-shift"><span class="std std-numref">Figure 5.6</span></a> for an illustration.</p>
<figure class="align-default" id="id34">
<span id="fig-scale-shift"></span><img alt="../_images/scale-shift-11.png" src="../_images/scale-shift-11.png" />
<figcaption>
<p><span class="caption-number">Figure 5.6 </span><span class="caption-text">Scaled and shifted versions of an example vector.</span><a class="headerlink" href="#id34" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Let <span class="math">\(\boldsymbol{y}=c \boldsymbol{x}+t\)</span>
and let <span class="math">\(\bar{x}, \bar{y}, s_x, s_y\)</span> denote the vectors’
arithmetic means and standard deviations.
The following properties hold.</p>
<ul class="simple">
<li><p>The arithmetic mean and all the quantiles (including, of course,
the median), are equivariant with respect to translation and scaling;
it holds, for instance, <span class="math">\(\bar{y} = c \bar{x} + t\)</span>.</p></li>
<li><p>The standard deviation, the interquartile range, and the
range are invariant to translations and equivariant to scaling;
e.g., <span class="math">\(s_y = c s_x\)</span>.</p></li>
</ul>
<p>As a byproduct, for the variance, we get…
<span class="math">\(s_y^2 = c^2 s_x^2\)</span>.</p>
</div>
<section id="standardisation-and-z-scores">
<h4><span class="section-number">5.3.2.1. </span>Standardisation and z-scores<a class="headerlink" href="#standardisation-and-z-scores" title="Link to this heading">#</a></h4>
<p>A <em>standardised</em> version of a vector <span class="math">\(\boldsymbol{x}=(x_1,\dots,x_n)\)</span>
consists in subtracting, from each element, the sample arithmetic mean
(which we call <em>centring</em>) and then dividing it by the standard deviation,
i.e., <span class="math">\(\boldsymbol{z}=(\boldsymbol{x}-\bar{x})/s\)</span>.</p>
<p>Thus, we transform each <span class="math">\(x_i\)</span> to obtain:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
z_i = \frac{x_i-\bar{x}}{s}.
\]</div>
</div>
<p>Consider again the female heights dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">heights</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span> <span class="c1"># preview</span>
<span class="c1">## array([157. , 167.4, 159.6, 168.5, 147.8])</span>
</pre></div>
</div>
<p>whose mean <span class="math">\(\bar{x}\)</span> and standard deviation <span class="math">\(s\)</span> are equal to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">heights</span><span class="p">)</span>
<span class="c1">## (160.13679222932953, 7.062021850008261)</span>
</pre></div>
</div>
<p>With <strong class="program">numpy</strong>, standardisation is as simple
as applying two aggregation functions and two arithmetic operations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">heights_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">heights</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">heights</span><span class="p">)</span>
<span class="n">heights_std</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span>  <span class="c1"># preview</span>
<span class="c1">## array([-0.44417764,  1.02848843, -0.07601113,  1.18425119, -1.74692071])</span>
</pre></div>
</div>
<p>What we obtained is sometimes referred to as the <em>z-scores</em>.
They are nicely interpretable:</p>
<ul class="simple">
<li><p>z-score of 0 corresponds to an observation equal to the sample mean
(perfectly average);</p></li>
<li><p>z-score of 1 is obtained for a datum 1 standard deviation
above the mean;</p></li>
<li><p>z-score of -2 means that it is a value 2 standard deviations
below the mean;</p></li>
</ul>
<p>and so forth.</p>
<p>Because of the way they emerge,
the mean of the z-scores is always 0 and standard deviation is 1
(up to a tiny numerical error, as usual; see <a class="reference internal" href="#sec-fp-error"><span class="std std-numref">Section 5.5.6</span></a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights_std</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">heights_std</span><span class="p">)</span>
<span class="c1">## (1.8920872660373198e-15, 1.0)</span>
</pre></div>
</div>
<p>Even though the original <code class="docutils literal notranslate"><span class="pre">heights</span></code> were measured in centimetres,
the z-scores are <em>unitless</em> (centimetres divided by centimetres).</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Standardisation enables the comparison of measurements on different scales
(think: height in centimetres vs weight in kilograms
or apples vs oranges). It makes the most sense for bell-shaped
distributions, in particular normally-distributed ones.
<a class="reference internal" href="230-distribution.html#sec-three-sigma"><span class="std std-numref">Section 6.1.2</span></a> will introduce the <span class="math">\(2\sigma\)</span> rule for the
normal family (but not necessarily other models!).
We will learn that we can <em>expect</em> that 95% of observations
have z-scores between -2 and 2.
Further, z-scores less than -3 and greater than 3 are highly unlikely.</p>
</div>
<div class="proof proof-type-exercise" id="id35">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.9</span>
        
    </div><div class="proof-content">
<p>We have a patient whose height z-score is 1 and
weight z-score is -1. How can we interpret this information?</p>
</div></div><div class="proof proof-type-exercise" id="id36">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.10</span>
        
    </div><div class="proof-content">
<p>What about a patient whose weight z-score is 0
but BMI z-score is 2?</p>
</div></div><p>On a side note, sometimes we might be interested in performing some form
of <em>robust</em> standardisation (e.g., for data with outliers or skewed).
In such a case, we can replace the mean with the median
and the standard deviation with the IQR.</p>
</section>
<section id="min-max-scaling-and-clipping">
<h4><span class="section-number">5.3.2.2. </span>Min-max scaling and clipping<a class="headerlink" href="#min-max-scaling-and-clipping" title="Link to this heading">#</a></h4>
<p>A less frequently but still noteworthy transformation
is called <em>min-max scaling</em> and
involves subtracting the minimum
and then dividing by the range, <span class="math">\((x-x_{(1)})/(x_{(n)}-x_{(1)})\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.33</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="c1">## array([0.   , 0.4  , 1.   , 0.034, 0.35 , 0.46 ])</span>
</pre></div>
</div>
<p>Here, the smallest value is mapped to 0 and the largest becomes equal to 1.
Let us stress that, in this context, 0.5 does not represent
the value which is equal to the mean (unless we are incredibly lucky).</p>
<div style="margin-top: 1em"></div><p>Also, <em>clipping</em> can be used to replace all values less than
0 with 0 and those greater than 1 with 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">## array([0.  , 0.5 , 1.  , 0.  , 0.25, 0.8 ])</span>
</pre></div>
</div>
<p>The function is, of course, flexible.
Another popular choice is clipping to <span class="math">\([-1, 1]\)</span>.
It can also be composed by means of the vectorised pairwise
minimum and maximum functions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="c1">## array([0.  , 0.5 , 1.  , 0.  , 0.25, 0.8 ])</span>
</pre></div>
</div>
</section>
<section id="normalisation-l-2-dividing-by-magnitude">
<span id="sec-normalisation"></span><h4><span class="section-number">5.3.2.3. </span>Normalisation (<span class="math">\(l_2\)</span>; dividing by magnitude)<a class="headerlink" href="#normalisation-l-2-dividing-by-magnitude" title="Link to this heading">#</a></h4>
<p><em>Normalisation</em> is the scaling of a given vector so that it is of
<em>unit length</em>. Usually, by <em>length</em> we mean the square root of the sum of
squares, i.e., the Euclidean (<span class="math">\(l_2\)</span>) norm also known as the <em>magnitude</em>:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
\| (x_1,\dots,x_n) \| = \sqrt{
x_1^2 + x_2^2 + \dots + x_n^2
} = \sqrt{
\sum_{i=1}^n x_i^2
}.
\]</div>
</div>
<p>Its special case for <span class="math">\(n=2\)</span> we know well from high school:
the length of a vector <span class="math">\((a,b)\)</span>
is <span class="math">\(\sqrt{a^2+b^2}\)</span>, e.g., <span class="math">\(\|(1, 2)\| = \sqrt{5} \simeq 2.236\)</span>.
Also, we are advised to program our brains so that when
we see <span class="math">\(\| \boldsymbol{x} \|^2\)</span> next time, we immediately
think of the <em>sum of squares</em>.</p>
<p>Consequently, a normalised vector:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
\frac{\boldsymbol{x}}{\| \boldsymbol{x} \|} =
\left(
\frac{x_1}{\| \boldsymbol{x} \|},
\frac{x_2}{\| \boldsymbol{x} \|},
\dots,
\frac{x_n}{\| \boldsymbol{x} \|}
\right),
\]</div>
</div>
<p>can be determined via:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>  <span class="c1"># example vector</span>
<span class="n">x</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>  <span class="c1"># x divided by the Euclidean norm of x</span>
<span class="c1">## array([ 0.13834289,  0.69171446, -0.55337157,  0.27668579,  0.34585723])</span>
</pre></div>
</div>
<div class="proof proof-type-exercise" id="id37">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.11</span>
        
    </div><div class="proof-content">
<p>Normalisation is similar to standardisation if data are
already centred (when the mean was subtracted). Show that we can obtain one
from the other via the scaling by <span class="math">\(\sqrt{n}\)</span>.</p>
</div></div><div class="admonition important">
<p class="admonition-title">Important</p>
<p>A common confusion is that normalisation is supposed to make
data <em>more normally</em> distributed. This is not the case<a class="footnote-reference brackets" href="#footboxcox" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>,
as we only scale (stretch or shrink) the observations here.</p>
</div>
</section>
<section id="normalisation-l-1-dividing-by-sum">
<h4><span class="section-number">5.3.2.4. </span>Normalisation (<span class="math">\(l_1\)</span>; dividing by sum)<a class="headerlink" href="#normalisation-l-1-dividing-by-sum" title="Link to this heading">#</a></h4>
<p>At other times, we might be interested in considering
the Manhattan (<span class="math">\(l_1\)</span>) norm:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
\| (x_1,\dots,x_n) \|_1 = |x_1| + |x_2| + \dots + |x_n| = \sum_{i=1}^n |x_i|,
\]</div>
</div>
<p>being the sum of absolute values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="c1">## array([ 0.06896552,  0.34482759, -0.27586207,  0.13793103,  0.17241379])</span>
</pre></div>
</div>
<p><span class="math">\(l_1\)</span> normalisation is frequently applied on vectors of nonnegative values,
whose normalised versions can be interpreted as <em>probabilities</em>
or <em>proportions</em>: values between 0 and 1 which sum to 1 (or, equivalently,
100%).</p>
<div class="proof proof-type-example" id="id38">

    <div class="proof-title">
        <span class="proof-type">Example 5.12</span>
        
    </div><div class="proof-content">
<p>Given some binned data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">heights</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">170</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>  <span class="c1"># counts</span>
<span class="c1">## [ 306 1776 1773  366]</span>
</pre></div>
</div>
<p>We can convert the counts to empirical probabilities:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">c</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>   <span class="c1"># np.abs is not needed here</span>
<span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="c1">## [0.07249467 0.42075338 0.42004264 0.08670931]</span>
</pre></div>
</div>
<p>We did not apply <strong class="program">numpy.abs</strong> because the values were already nonnegative.</p>
</div></div></section>
</section>
<section id="vector-vector-case">
<h3><span class="section-number">5.3.3. </span>Vector-vector case<a class="headerlink" href="#vector-vector-case" title="Link to this heading">#</a></h3>
<p>So far we have been applying `<strong class="command">*</strong>`, `<strong class="command">+</strong>`, etc.,
on vectors and scalars only.
All arithmetic operators can also be applied on two vectors of equal lengths.
In such a case, they will act <em>elementwisely</em>:
taking each element from the first operand
and combining it with the <em>corresponding</em> element from the second argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">])</span>
<span class="c1">## array([   20,   300,  4000, 50000])</span>
</pre></div>
</div>
<p>We see that the first element in the left operand (2)
was multiplied by the first element in the right operand (10).
Then, we multiplied 3 by 100 (the second corresponding elements),
and so forth.</p>
<p>Such a behaviour of the binary operators
is inspired by the usual convention in vector algebra
where applying <span class="math">\(+\)</span> (or <span class="math">\(-\)</span>) on <span class="math">\(\boldsymbol{x}=(x_1,\dots,x_n)\)</span>
and <span class="math">\(\boldsymbol{y}=(y_1,\dots,y_n)\)</span> means exactly:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
\boldsymbol{x}+\boldsymbol{y} = (x_1+y_1, x_2+y_2, \dots, x_n+y_n).
\]</div>
</div>
<p>Using other operators this way (elementwisely)
is less standard in mathematics (for instance multiplication
might denote the dot product), but in <strong class="program">numpy</strong>
it is really convenient.</p>
<div class="proof proof-type-example" id="id39">

    <div class="proof-title">
        <span class="proof-type">Example 5.13</span>
        
    </div><div class="proof-content">
<p>Let us compute
the value of the expression
<span class="math">\(h = - (p_1\, \log p_1 + \dots + p_n\, \log p_n)\)</span>,
i.e., <span class="math">\(h=-\sum_{i=1}^n p_i\, \log p_i\)</span> (the entropy):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">])</span>  <span class="c1"># example vector</span>
<span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="c1">## 1.6790818544987114</span>
</pre></div>
</div>
<p>The above involves the use of a unary vectorised
minus (change sign), an aggregation function (sum),
a vectorised mathematical function (log),
and an elementwise multiplication of two vectors of the same lengths.</p>
</div></div><div class="proof proof-type-example" id="id40">

    <div class="proof-title">
        <span class="proof-type">Example 5.14</span>
        
    </div><div class="proof-content">
<p>Let us assume that – for whatever reason – we would like to
plot two mathematical functions, the sine, <span class="math">\(f(x)= \sin x\)</span>,
and a polynomial of degree 7, <span class="math">\(g(x) = x - x^3/6 + x^5/120 - x^7/5040\)</span>
for <span class="math">\(x\)</span> in the interval <span class="math">\([-\pi, 3\pi/2]\)</span>.</p>
<p>To do this, we can probe the values of <span class="math">\(f\)</span> and <span class="math">\(g\)</span> at sufficiently many points
using the vectorised operations discussed so far
and then use the <strong class="command">matplotlib.pyplot.plot</strong> function
to draw what we see in <a class="reference internal" href="#fig-vectorised-easy"><span class="std std-numref">Figure 5.7</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mf">1.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>  <span class="c1"># many points in the said interval</span>
<span class="n">yf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">yg</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="o">/</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">**</span><span class="mi">5</span><span class="o">/</span><span class="mi">120</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">7</span><span class="o">/</span><span class="mi">5040</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yf</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;f(x)&quot;</span><span class="p">)</span>  <span class="c1"># black solid line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yg</span><span class="p">,</span> <span class="s1">&#39;r:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;g(x)&quot;</span><span class="p">)</span>  <span class="c1"># red dotted line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id41">
<span id="fig-vectorised-easy"></span><img alt="../_images/vectorised-easy-13.png" src="../_images/vectorised-easy-13.png" />
<figcaption>
<p><span class="caption-number">Figure 5.7 </span><span class="caption-text">With vectorised functions, it is easy to generate plots like this one. We used different line styles so that the plot is readable also when printed in black and white.</span><a class="headerlink" href="#id41" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Decreasing the number of points in <code class="docutils literal notranslate"><span class="pre">x</span></code> will reveal that the
plotting function merely draws a series of straight-line segments.
Computer graphics is essentially discrete.</p>
</div></div><div class="proof proof-type-exercise" id="id42">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.15</span>
        
    </div><div class="proof-content">
<p>Using a single line of code, compute the vector of BMIs of all persons
based on the
<a class="reference external" href="https://github.com/gagolews/teaching-data/raw/master/marek/nhanes_adult_female_height_2020.txt"><code class="docutils literal notranslate"><span class="pre">nhanes_adult_female_height_2020</span></code></a>
and
<a class="reference external" href="https://github.com/gagolews/teaching-data/raw/master/marek/nhanes_adult_female_weight_2020.txt"><code class="docutils literal notranslate"><span class="pre">nhanes_adult_female_weight_2020</span></code></a> datasets.
It is assumed that the <span class="math">\(i\)</span>-th elements therein both refer to the same
person.</p>
</div></div></section>
</section>
<section id="indexing-vectors">
<span id="sec-vector-indexing"></span><h2><span class="section-number">5.4. </span>Indexing vectors<a class="headerlink" href="#indexing-vectors" title="Link to this heading">#</a></h2>
<p>Recall from <a class="reference internal" href="130-sequential.html#sec-extract-elem"><span class="std std-numref">Section 3.2.1</span></a> and <a class="reference internal" href="130-sequential.html#sec-slicing"><span class="std std-numref">Section 3.2.2</span></a>
that sequential objects in Python (lists, tuples, strings, ranges)
support indexing using scalars and slices:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
<span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># scalar index – extract</span>
<span class="c1">## 20</span>
<span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># slice index – subset</span>
<span class="c1">## [20]</span>
</pre></div>
</div>
<p><strong class="program">numpy</strong> vectors support two <em>additional</em> indexing schemes:
using integer and boolean sequences.</p>
<section id="integer-indexing">
<h3><span class="section-number">5.4.1. </span>Integer indexing<a class="headerlink" href="#integer-indexing" title="Link to this heading">#</a></h3>
<p>Indexing with a single integer <em>extracts</em>
a particular element:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>   <span class="c1"># first</span>
<span class="c1">## 10</span>
<span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>   <span class="c1"># second</span>
<span class="c1">## 20</span>
<span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># last</span>
<span class="c1">## 50</span>
</pre></div>
</div>
<p>We can also use lists of vectors of integer indexes,
which return a subvector with elements at the specified indexes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">[</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">]</span>
<span class="c1">## array([10])</span>
<span class="n">x</span><span class="p">[</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="p">]</span>
<span class="c1">## array([10, 20, 50, 10, 20, 10, 10])</span>
<span class="n">x</span><span class="p">[</span> <span class="p">[]</span> <span class="p">]</span>
<span class="c1">## array([], dtype=int64)</span>
</pre></div>
</div>
<p>We added some spaces between the square brackets for readability only:
e.g., <code class="docutils literal notranslate"><span class="pre">x[[0]]</span></code> could seem slightly more obscure.
(What are these double square brackets?
Nah, it is a list inside the index operator.)</p>
</section>
<section id="logical-indexing">
<h3><span class="section-number">5.4.2. </span>Logical indexing<a class="headerlink" href="#logical-indexing" title="Link to this heading">#</a></h3>
<p>Subsetting using a logical vector of the same length as the indexed
vector is possible too:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">[</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span> <span class="p">]</span>
<span class="c1">## array([10, 30, 40])</span>
</pre></div>
</div>
<p>This returned the first, third, and fourth element
(select first, omit second, select third, select fourth, omit fifth).</p>
<p>This is particularly useful as a <em>data filtering</em> technique.
Knowing that the relational vector operators
`<strong class="command">&lt;</strong>`, `<strong class="command">&lt;=</strong>`, `<strong class="command">==</strong>`,
`<strong class="command">!=</strong>`, `<strong class="command">&gt;=</strong>`, and `<strong class="command">&gt;</strong>`
are performed elementwisely,
just like `<strong class="command">+</strong>`, `<strong class="command">*</strong>`, etc.
For instance:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">30</span>
<span class="c1">## array([False, False,  True,  True,  True])</span>
</pre></div>
</div>
<p>Thus, we can write:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">[</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">30</span> <span class="p">]</span>
<span class="c1">## array([30, 40, 50])</span>
</pre></div>
</div>
<p>to mean “select the elements in <code class="docutils literal notranslate"><span class="pre">x</span></code> which are not less than 30”.</p>
<div style="margin-top: 1em"></div><p>Of course, the indexed vector and the vector
specifying the <em>filter</em> do not<a class="footnote-reference brackets" href="#footnononstandard" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a> have to be the same:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>  <span class="c1"># whatever</span>
<span class="n">y</span>  <span class="c1"># equal to 0 if a number is a multiply of 10 times an even number</span>
<span class="c1">## array([1., 0., 1., 0., 1.])</span>
<span class="n">x</span><span class="p">[</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">]</span>
<span class="c1">## array([20, 40])</span>
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Sadly, if we wish to combine many logical vectors, we cannot
use the <strong class="command">and</strong>, <strong class="command">or</strong>, and <strong class="command">not</strong> operators.
They are not vectorised (this is a limitation at the language level).</p>
<p>Instead, in <strong class="program">numpy</strong>, we use the `<strong class="command">&amp;</strong>`, `<strong class="command">|</strong>`,
and `<strong class="command">~</strong>` operators.
Unfortunately, they have a lower order of precedence than
`<strong class="command">&lt;</strong>`, `<strong class="command">&lt;=</strong>`, `<strong class="command">==</strong>`, etc.
Therefore, the bracketing of the comparisons is obligatory.</p>
</div>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">[</span> <span class="p">(</span><span class="mi">20</span> <span class="o">&lt;=</span> <span class="n">x</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">40</span><span class="p">)</span> <span class="p">]</span>  <span class="c1"># check what happens if we skip the brackets</span>
<span class="c1">## array([20, 30, 40])</span>
</pre></div>
</div>
<p>means “elements in <code class="docutils literal notranslate"><span class="pre">x</span></code> between 20 and 40”
(greater than or equal to 20 and less than or equal to 40).</p>
<p>Also:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">15</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">35</span><span class="p">)</span> <span class="p">])</span>
<span class="c1">## 3</span>
</pre></div>
</div>
<p>Computes the number of elements in <code class="docutils literal notranslate"><span class="pre">x</span></code> less than 15 or greater than 35
(not between 15 and 35).</p>
<div class="proof proof-type-exercise" id="id43">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.16</span>
        
    </div><div class="proof-content">
<p>Compute the BMIs only of the women whose height is between 150 and 170 cm.</p>
</div></div></section>
<section id="slicing">
<h3><span class="section-number">5.4.3. </span>Slicing<a class="headerlink" href="#slicing" title="Link to this heading">#</a></h3>
<p>Just as with ordinary lists, slicing with `<strong class="command">:</strong>`
fetches the elements at indexes in a given range like <code class="docutils literal notranslate"><span class="pre">from:to</span></code>
or <code class="docutils literal notranslate"><span class="pre">from:to:by</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>  <span class="c1"># first three elements</span>
<span class="c1">## array([10, 20, 30])</span>
<span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># every second element</span>
<span class="c1">## array([10, 30, 50])</span>
<span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>  <span class="c1"># from the second (inclusive) to the fifth (exclusive)</span>
<span class="c1">## array([20, 30, 40])</span>
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>For efficiency reasons, slicing returns a
<em>view</em> of existing data. It does not have to make an independent
copy of the subsetted elements: by definition, sliced ranges are <em>regular</em>.</p>
</div>
<p>In other words, both <code class="docutils literal notranslate"><span class="pre">x</span></code> and its sliced version share the same memory.
This is important when we apply operations which modify a
given vector in place, such as the <code class="docutils literal notranslate"><span class="pre">sort</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">y</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">10</span>  <span class="c1"># modifies parts of y in place</span>
<span class="n">y</span>  <span class="c1"># has changed</span>
<span class="c1">## array([60,  4, 80,  5, 10,  3, 20,  9, 70])</span>
</pre></div>
</div>
<p>This multiplied every second element in <code class="docutils literal notranslate"><span class="pre">y</span></code> by 10
(i.e., <code class="docutils literal notranslate"><span class="pre">[6,</span> <span class="pre">8,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">7]</span></code>).
On the other hand, indexing with an integer or logical
vector always returns a copy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span> <span class="p">]</span> <span class="o">*=</span> <span class="mi">10</span>  <span class="c1"># modifies a new object and then forgets about it</span>
<span class="n">y</span>  <span class="c1"># has not changed since the last modification</span>
<span class="c1">## array([60, 40, 80, 50, 10, 30, 20, 90, 70])</span>
</pre></div>
</div>
<p>This <em>did not</em> modify the original vector, because
we applied `<strong class="command">*=</strong>` on a different object,
which has not even been memorised after that operation took place.</p>
</section>
</section>
<section id="other-operations">
<h2><span class="section-number">5.5. </span>Other operations<a class="headerlink" href="#other-operations" title="Link to this heading">#</a></h2>
<section id="cumulative-sums-and-iterated-differences">
<span id="sec-cumsum"></span><h3><span class="section-number">5.5.1. </span>Cumulative sums and iterated differences<a class="headerlink" href="#cumulative-sums-and-iterated-differences" title="Link to this heading">#</a></h3>
<p>Recall that the `<strong class="command">+</strong>` operator acts on two vectors elementwisely
and that the <strong class="command">numpy.sum</strong> function aggregates all values into
a single one. We have a similar function, but vectorised
in a slightly different fashion. Namely, <strong class="command">numpy.cumsum</strong>
returns the vector of <em>cumulative sums</em>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="c1">## array([5, 8, 4, 5, 6, 9])</span>
</pre></div>
</div>
<p>This gave, in this order: the first element, the sum of first two elements,
the sum of first three elements, …, the sum of all elements.</p>
<div style="margin-top: 1em"></div><p><em>Iterated differences</em> are a somewhat inverse operation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
<span class="c1">## array([ 3, -4,  1,  1,  3])</span>
</pre></div>
</div>
<p>It returned the difference between the second and the first element,
then the difference between the third and the second, and so forth.
The resulting vector is one element shorter than the input one.</p>
<div style="margin-top: 1em"></div><p>We often make use of cumulative sums and iterated differences when
processing time series, e.g., stock exchange data
(e.g., by how much the price changed since the previous day?;
<a class="reference internal" href="530-time-series.html#sec-diff-ts"><span class="std std-numref">Section 16.3.1</span></a>)
or determining cumulative distribution functions (<a class="reference internal" href="210-vector.html#sec-ecdf"><span class="std std-numref">Section 4.3.8</span></a>).</p>
</section>
<section id="sorting">
<h3><span class="section-number">5.5.2. </span>Sorting<a class="headerlink" href="#sorting" title="Link to this heading">#</a></h3>
<p>The <strong class="command">numpy.sort</strong> function returns a sorted copy
of a given vector, i.e., determines the order statistics.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">## array([10, 20, 30, 30, 40, 50, 50])</span>
</pre></div>
</div>
<p>The <strong class="command">sort</strong> method (as in: <code class="docutils literal notranslate"><span class="pre">x.sort()</span></code>), on the other hand,
sorts the vector in place (and returns nothing).</p>
<div class="proof proof-type-exercise" id="id44">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.17</span>
        
    </div><div class="proof-content">
<p>Readers interested more in chaos than in bringing order
should give <strong class="command">numpy.random.permutation</strong> a try.
This function shuffles the elements in a given vector.</p>
</div></div></section>
<section id="dealing-with-tied-observations">
<span id="sec-ties"></span><h3><span class="section-number">5.5.3. </span>Dealing with tied observations<a class="headerlink" href="#dealing-with-tied-observations" title="Link to this heading">#</a></h3>
<p>Some statistical methods, especially for continuous data<a class="footnote-reference brackets" href="#footconttie" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a>,
assume that all observations in a vector are unique, i.e.,
there are no <em>ties</em>. In real life, however, some values
might be recorded multiple times. For instance, two marathoners
might finish their runs in exactly the same time,
data can be rounded up to a certain number
of fractional digits, or it just happens that observations are inherently
integer. Therefore, we should be able to detect duplicated entries.</p>
<p><strong class="command">numpy.unique</strong> is a workhorse for dealing with tied observations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">40</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">30</span><span class="p">])</span>
<span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">## array([10, 20, 30, 40, 50, 70])</span>
</pre></div>
</div>
<p>Returns a <em>sorted</em><a class="footnote-reference brackets" href="#footpandasunique" id="id16" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> version of
a given vector with duplicates removed.</p>
<p>We can also get the corresponding counts:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># returns a tuple of length 2</span>
<span class="c1">## (array([10, 20, 30, 40, 50, 70]), array([3, 2, 3, 5, 1, 1]))</span>
</pre></div>
</div>
<p>It can help determine if all the values in a vector are unique:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">## False</span>
</pre></div>
</div>
<div class="proof proof-type-exercise" id="id45">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.18</span>
        
    </div><div class="proof-content">
<p>Play with the <code class="docutils literal notranslate"><span class="pre">return_index</span></code> argument to <strong class="command">numpy.unique</strong>.
It permits pinpointing the indexes of the first occurrences
of each unique value.</p>
</div></div></section>
<section id="determining-the-ordering-permutation-and-ranking">
<h3><span class="section-number">5.5.4. </span>Determining the ordering permutation and ranking<a class="headerlink" href="#determining-the-ordering-permutation-and-ranking" title="Link to this heading">#</a></h3>
<p><strong class="command">numpy.argsort</strong> returns a sequence of indexes that
lead to an ordered version of a given vector
(i.e., an ordering permutation).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">## array([2, 4, 1, 5, 3, 0, 6])</span>
</pre></div>
</div>
<p>Which means that the smallest element is at index 2,
then the second smallest is at index 4, the third smallest at index 1, etc.
Therefore:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
<span class="c1">## array([10, 20, 30, 30, 40, 50, 50])</span>
</pre></div>
</div>
<p>is equivalent to <strong class="command">numpy.sort</strong><code class="code docutils literal notranslate"><span class="pre">(x)</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>(**)
If there are tied observations in a vector <code class="docutils literal notranslate"><span class="pre">x</span></code>,
<strong class="command">numpy.argsort</strong><code class="code docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">kind=&quot;stable&quot;)</span></code> will use
a <em>stable</em> sorting algorithm
(<a class="reference external" href="https://github.com/python/cpython/blob/3.7/Objects/listsort.txt">timsort</a>,
a variant of mergesort), which guarantees that the ordering
permutation is unique: tied elements are placed in the order of appearance.</p>
</div>
<div style="margin-top: 1em"></div><p>Next, <strong class="command">scipy.stats.rankdata</strong> returns a vector of <em>ranks</em>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">rankdata</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">## array([6.5, 3.5, 1. , 5. , 2. , 3.5, 6.5])</span>
</pre></div>
</div>
<p>Element 10 is the smallest (“the winner”, say, the quickest racer).
Hence, it ranks first.
The two tied elements equal to 30 are the third/fourth on the podium
(ex aequo). Thus, they receive the average rank of 3.5.
And so on.</p>
<p>On a side note, there are many methods in nonparametric statistics
(those that do not make any too particular assumptions
about the underlying data distribution) that are based on ranks.
In particular, <a class="reference internal" href="330-relationship.html#sec-spearman"><span class="std std-numref">Section 9.1.4</span></a> will cover the Spearman correlation
coefficient.</p>
<div class="proof proof-type-exercise" id="id46">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.19</span>
        
    </div><div class="proof-content">
<p>Consult the manual page of <strong class="program">scipy.stats.rankdata</strong>
and test various methods for dealing with ties.</p>
</div></div><div class="proof proof-type-exercise" id="id47">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.20</span>
        
    </div><div class="proof-content">
<p>What is the interpretation of a rank divided by the length
of the sample?</p>
</div></div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>(**)
Readers with some background in discrete mathematics
will be interested in the fact that calling <strong class="command">numpy.argsort</strong>
on a vector representing a permutation of elements generates its inverse.
In particular,
<strong class="command">np.argsort</strong><code class="code docutils literal notranslate"><span class="pre">(</span></code><strong class="command">np.argsort</strong><code class="code docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">kind=&quot;stable&quot;))+1</span></code>
is equivalent to
<strong class="command">scipy.stats.rankdata</strong><code class="code docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">method=&quot;ordinal&quot;)</span></code>.</p>
</div>
</section>
<section id="searching-for-certain-indexes-argmin-argmax">
<h3><span class="section-number">5.5.5. </span>Searching for certain indexes (argmin, argmax)<a class="headerlink" href="#searching-for-certain-indexes-argmin-argmax" title="Link to this heading">#</a></h3>
<p><strong class="command">numpy.argmin</strong> and <strong class="command">numpy.argmax</strong> return the index at
which we can find the smallest and the largest observation
in a given vector.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">## (2, 0)</span>
</pre></div>
</div>
<p>If there are tied observations, the smallest index is returned.</p>
<p>Using mathematical notation, the former is denoted by:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
i = \mathrm{arg}\min_j x_j,
\]</div>
</div>
<p>and read it as: let <span class="math">\(i\)</span> be the index of the smallest element in the sequence.
Alternatively, it is the <em>argument of the minimum</em>, whenever:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
x_i = \min_j x_j,
\]</div>
</div>
<p>i.e., the <span class="math">\(i\)</span>-th element is the smallest.</p>
<div style="margin-top: 1em"></div><p>We can use <strong class="command">numpy.flatnonzero</strong> to fetch the indexes
where a logical vector has elements equal to <code class="docutils literal notranslate"><span class="pre">True</span></code>
(<a class="reference internal" href="420-categorical.html#sec-binary-logical"><span class="std std-numref">Section 11.1.2</span></a> mentions that a value equal
to zero is treated as the logical <code class="docutils literal notranslate"><span class="pre">False</span></code>, and as <code class="docutils literal notranslate"><span class="pre">True</span></code> in all
other cases).
For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="c1">## array([0, 6])</span>
</pre></div>
</div>
<p>It is a version of <strong class="command">numpy.argmax</strong> that lets us decide
what we would like to do with the tied maxima (there are two).</p>
<div class="proof proof-type-exercise" id="id48">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.21</span>
        
    </div><div class="proof-content">
<p>Let <code class="docutils literal notranslate"><span class="pre">x</span></code> be a vector with possible ties.
Create an expression that returns a randomly chosen index
pinpointing one of the sample maxima.</p>
</div></div></section>
<section id="dealing-with-round-off-and-measurement-errors">
<span id="sec-fp-error"></span><h3><span class="section-number">5.5.6. </span>Dealing with round-off and measurement errors<a class="headerlink" href="#dealing-with-round-off-and-measurement-errors" title="Link to this heading">#</a></h3>
<p>Mathematics tells us (the easy proof is left as an exercise for the reader)
that a centred version of a given vector
<span class="math">\(\boldsymbol{x}\)</span>, <span class="math">\(\boldsymbol{y} = \boldsymbol{x}-\bar{x}\)</span>,
has the arithmetic mean of 0, i.e., <span class="math">\(\bar{y}=0\)</span>.</p>
<p>Of course, it is also true on a computer. Or is it?</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">heights_centred</span> <span class="o">=</span> <span class="p">(</span><span class="n">heights</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights_centred</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
<span class="c1">## False</span>
</pre></div>
</div>
<p>The average is actually equal to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights_centred</span><span class="p">)</span>
<span class="c1">## 1.3359078775153175e-14</span>
</pre></div>
</div>
<p>which is <em>almost</em> zero (0.0000000000000134), but not <em>exactly</em> zero
(it is zero for an engineer, not a mathematician).
We saw a similar result in <a class="reference internal" href="#sec-standardisation"><span class="std std-numref">Section 5.3.2</span></a>,
when performing standardisation (which involves centring).</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>All floating-point operations on a computer<a class="footnote-reference brackets" href="#footieee754" id="id17" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a> (not only in Python)
are performed with <em>finite</em> precision of 15–17 decimal digits.</p>
</div>
<p>We know it from school – for example, some fractions cannot
be represented as decimals. When asked to add or multiply
them, we will always have to apply some rounding that ultimately
leads to precision loss. We know that <span class="math">\(1/3 + 1/3 + 1/3 = 1\)</span>,
but using a decimal representation with one fractional digit,
we get <span class="math">\(0.3+0.3+0.3=0.9\)</span>. With two digits, we obtain <span class="math">\(0.33+0.33+0.33=0.99\)</span>.
And so on.
This sum will never be equal exactly to 1 when using a finite precision.</p>
<p>Moreover, errors induced in one operation will propagate onto further ones.
Most often they cancel out, but in extreme cases, they can lead to
undesirable consequences (like for some model matrices
in linear regression; see <a class="reference internal" href="330-relationship.html#sec-ill-condition"><span class="std std-numref">Section 9.2.9</span></a>).</p>
<p>There is no reason to panic, though. The rule to remember is:</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>As the floating-point values are precise up to a few decimal digits,
we must refrain from comparing them using the `<strong class="command">==</strong>`
operator, which tests for <em>exact</em> equality.</p>
</div>
<p>When a comparison is needed, we need to take some error margin
into account. Ideally, instead of testing <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">==</span> <span class="pre">y</span></code>, we either
inspect the <em>absolute error</em>:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
|x-y| \le \varepsilon,
\]</div>
</div>
<p>or, assuming <span class="math">\(y\neq 0\)</span>, the <em>relative error</em>:</p>
<div class="math-wrapper docutils container">
<div class="math">
\[
\frac{|x-y|}{|y|} \le \varepsilon,
\]</div>
</div>
<p>where <span class="math">\(\varepsilon\)</span> is some small error margin.</p>
<p>For instance, <strong class="command">numpy.allclose</strong><code class="code docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y)</span></code> checks (by default)
if for all corresponding elements in both vectors it holds
<strong class="command">numpy.abs</strong><code class="code docutils literal notranslate"><span class="pre">(x-y)</span> <span class="pre">&lt;=</span> <span class="pre">1e-8</span> <span class="pre">+</span> <span class="pre">1e-5*</span></code><strong class="command">numpy.abs</strong><code class="code docutils literal notranslate"><span class="pre">(y)</span></code>,
which is a combination of both tests.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">heights_centred</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="c1">## True</span>
</pre></div>
</div>
<p>To avoid sorrow surprises, even the testing of inequalities
like <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">0</span></code> should rather be performed as, say, <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">1e-8</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Our data are often imprecise by nature.
When asked about people’s heights, rarely will they provide a non-integer
answer (assuming they know how tall they are and
are not lying about it, but it is a different story).
We will most likely get data rounded to 0 decimal digits.
In our dataset the precision is a bit higher:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">heights</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>  <span class="c1"># preview</span>
<span class="c1">## array([160.2, 152.7, 161.2, 157.4, 154.6, 144.7])</span>
</pre></div>
</div>
<p>But still, there is an inherent <em>observational error</em>.
Even if, for example, the mean thereof was computed exactly,
the fact that the inputs themselves are not necessarily ideal
makes the estimate <em>approximate</em> as well. We can only hope
that these errors will more or less cancel out in the computations.</p>
</div>
<div class="proof proof-type-exercise" id="id49">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.22</span>
        
    </div><div class="proof-content">
<p>Compute the BMIs of all females in the NHANES study.
Determine their arithmetic mean.
Compare it to the arithmetic mean computed for BMIs rounded to 1, 2, 3, 4,
etc., decimal digits.</p>
</div></div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>(*) Another problem is related to the fact that floats on a computer
use the binary base, not the decimal one. Therefore, some
fractional numbers that we <em>believe</em> to be representable exactly,
require an infinite number of bits. As a consequence, they are subject to
rounding.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">==</span> <span class="mf">0.3</span>  <span class="c1"># obviously</span>
<span class="c1">## False</span>
</pre></div>
</div>
<p>This is because <code class="docutils literal notranslate"><span class="pre">0.1</span></code>, <code class="docutils literal notranslate"><span class="pre">0.1+0.1+0.1</span></code>, and <code class="docutils literal notranslate"><span class="pre">0.3</span></code> are literally
represented as, respectively:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="mf">0.1</span><span class="si">:</span><span class="s2">.19f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="mf">0.1</span><span class="o">+</span><span class="mf">0.1</span><span class="o">+</span><span class="mf">0.1</span><span class="si">:</span><span class="s2">.19f</span><span class="si">}</span><span class="s2">, and </span><span class="si">{</span><span class="mf">0.3</span><span class="si">:</span><span class="s2">.19f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="c1">## 0.1000000000000000056, 0.3000000000000000444, and 0.2999999999999999889.</span>
</pre></div>
</div>
</div>
<p>A suggested introductory reference to the topic of numerical
inaccuracies is <span id="id18">[<a class="reference internal" href="999-bibliography.html#id140" title="Goldberg, D. (1991).  What every computer scientist should know about floating-point arithmetic. ACM Computing Surveys, 21(1):5–48. URL: https://perso.ens-lyon.fr/jean-michel.muller/goldberg.pdf.">41</a>]</span>; see also <span id="id19">[<a class="reference internal" href="999-bibliography.html#id139" title="Higham, N.J. (2002).  Accuracy and Stability of Numerical Algorithms. SIAM. DOI: 10.1137/1.9780898718027.">48</a>, <a class="reference internal" href="999-bibliography.html#id141" title="Knuth, D.E. (1997).  The Art of Computer Programming II: Seminumerical Algorithms. Addison-Wesley.">56</a>]</span>
for a more comprehensive treatment of numerical analysis.</p>
</section>
<section id="vectorising-scalar-operations-with-list-comprehensions">
<span id="sec-list-comprehension"></span><h3><span class="section-number">5.5.7. </span>Vectorising scalar operations with list comprehensions<a class="headerlink" href="#vectorising-scalar-operations-with-list-comprehensions" title="Link to this heading">#</a></h3>
<p><em>List comprehensions</em> of the form
<code class="docutils literal notranslate"><span class="pre">[</span> <span class="pre">expression</span> </code><strong class="command">for</strong><code class="code docutils literal notranslate"> <span class="pre">name</span> </code><strong class="command">in</strong><code class="code docutils literal notranslate"> <span class="pre">iterable</span> <span class="pre">]</span></code>
are part of base Python.
They create lists based on transformed versions
of individual elements in a given iterable object.
Hence, they might work in cases where a task at hand
cannot be solved by means of vectorised <strong class="program">numpy</strong> functions.</p>
<p>For example, here is a way to generate the squares of a few
positive natural numbers:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="n">i</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="p">]</span>
<span class="c1">## [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]</span>
</pre></div>
</div>
<p>The result can be passed to <strong class="command">numpy.array</strong> to convert it to a vector.</p>
<p>Further, given an example vector:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x</span>
<span class="c1">## array([ 0.86, -0.37, -0.63, -0.59,  0.14,  0.19,  0.93,  0.31,  0.5 ])</span>
</pre></div>
</div>
<p>If we wish to filter out all elements that are not positive, we can write:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">x</span> <span class="k">if</span> <span class="n">e</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">]</span>
<span class="c1">## [0.86, 0.14, 0.19, 0.93, 0.31, 0.5]</span>
</pre></div>
</div>
<div style="margin-top: 1em"></div><p>We can also use the ternary operator of the form
<code class="docutils literal notranslate"><span class="pre">x_true</span> </code><strong class="command">if</strong><code class="code docutils literal notranslate"> <span class="pre">cond</span> </code><strong class="command">else</strong><code class="code docutils literal notranslate"> <span class="pre">x_false</span></code>
to return either <code class="docutils literal notranslate"><span class="pre">x_true</span></code> or
<code class="docutils literal notranslate"><span class="pre">x_false</span></code> depending on the truth value of <code class="docutils literal notranslate"><span class="pre">cond</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">e</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="n">e</span><span class="o">**</span><span class="mf">0.5</span> <span class="k">if</span> <span class="n">e</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="o">-</span><span class="n">e</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span>
<span class="c1">## 1.4142135623730951</span>
</pre></div>
</div>
<p>Combined with a list comprehension, we can write, for instance:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="nb">round</span><span class="p">(</span><span class="n">e</span><span class="o">**</span><span class="mf">0.5</span> <span class="k">if</span> <span class="n">e</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="o">-</span><span class="n">e</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">x</span> <span class="p">]</span>
<span class="c1">## [0.93, 0.61, 0.79, 0.77, 0.37, 0.44, 0.96, 0.56, 0.71]</span>
</pre></div>
</div>
<p>This gave the square root of absolute values.</p>
<div style="margin-top: 1em"></div><p>There is also a tool which vectorises a scalar function
so that it can be used on <strong class="program">numpy</strong> vectors:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">clip01</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;clip to the unit interval&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>    <span class="k">return</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>        <span class="k">return</span> <span class="n">x</span>

<span class="n">clip01s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">clip01</span><span class="p">)</span>  <span class="c1"># returns a function object</span>
<span class="n">clip01s</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
<span class="c1">## array([0.3, 0. , 0.7, 1. , 1. ])</span>
</pre></div>
</div>
<p>In the above cases, it is much better (faster, more readable code)
to rely on vectorised <strong class="program">numpy</strong> functions.
Still, if the corresponding operations are unavailable
(e.g., string processing, reading many files),
list comprehensions provide a reasonable replacement therefor.</p>
<div class="proof proof-type-exercise" id="id50">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.23</span>
        
    </div><div class="proof-content">
<p>Write equivalent versions of the above expressions
using vectorised <strong class="program">numpy</strong> functions.</p>
</div></div><div class="proof proof-type-exercise" id="id51">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.24</span>
        
    </div><div class="proof-content">
<p>Implement the above expressions using base Python lists,
the <strong class="command">for</strong> loop and the <strong class="command">list.append</strong> method (start from
an empty list that will store the result).</p>
</div></div></section>
</section>
<section id="exercises">
<h2><span class="section-number">5.6. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<div class="proof proof-type-exercise" id="id52">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.25</span>
        
    </div><div class="proof-content">
<p>What are some benefits of using a <strong class="program">numpy</strong> vector
over an ordinary Python list? What are the drawbacks?</p>
</div></div><div class="proof proof-type-exercise" id="id53">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.26</span>
        
    </div><div class="proof-content">
<p>How can we interpret the possibly different values
of the arithmetic mean, median, standard deviation, interquartile range,
and skewness, when comparing between heights of men and women?</p>
</div></div><div class="proof proof-type-exercise" id="id54">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.27</span>
        
    </div><div class="proof-content">
<p>There is something scientific and magical about <em>numbers</em>
that make us approach them with some kind of respect.
However, taking into account that there are many possible data aggregates,
there is a risk that a party may be cherry-picking – reporting
the one that portrays the analysed entity in a good or bad light. For instance,
reporting the mean instead of the median or vice versa.
Is there anything that can be done about it?</p>
</div></div><div class="proof proof-type-exercise" id="id55">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.28</span>
        
    </div><div class="proof-content">
<p>Even though, mathematically speaking, all measures can be computed on all
data, it does not mean that it always makes sense to do so.
For instance, some distributions will have skewness of 0.
However, let us not automatically assume that they are delightfully
symmetric and bell-shaped (e.g., this can be a bimodal distribution).
We always ought to visualise our data.
Give some examples of datasets and measures where we should be critical
of the obtained aggregates.</p>
</div></div><div class="proof proof-type-exercise" id="id56">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.29</span>
        
    </div><div class="proof-content">
<p>Give some examples where simple data preprocessing
can drastically change the values of chosen sample aggregates.</p>
</div></div><div class="proof proof-type-exercise" id="id57">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.30</span>
        
    </div><div class="proof-content">
<p>Give the mathematical definitions, use cases, and interpretations
of standardisation, normalisation, and min-max scaling.</p>
</div></div><div class="proof proof-type-exercise" id="id58">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.31</span>
        
    </div><div class="proof-content">
<p>How are <strong class="command">numpy.log</strong> and <strong class="command">numpy.exp</strong> related to each other?
What about <strong class="command">numpy.log</strong> vs <strong class="command">numpy.log10</strong>,
<strong class="command">numpy.cumsum</strong> vs <strong class="command">numpy.diff</strong>,
<strong class="command">numpy.min</strong> vs <strong class="command">numpy.argmin</strong>,
<strong class="command">numpy.sort</strong> vs <strong class="command">numpy.argsort</strong>,  and
<strong class="command">scipy.stats.rankdata</strong> vs <strong class="command">numpy.argsort</strong>?</p>
</div></div><div class="proof proof-type-exercise" id="id59">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.32</span>
        
    </div><div class="proof-content">
<p>What is the difference between
<strong class="command">numpy.trunc</strong>, <strong class="command">numpy.floor</strong>, <strong class="command">numpy.ceil</strong>,
and <strong class="command">numpy.round</strong>?</p>
</div></div><div class="proof proof-type-exercise" id="id60">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.33</span>
        
    </div><div class="proof-content">
<p>What happens when we apply `<strong class="command">+</strong>` on two vectors of different
lengths?</p>
</div></div><div class="proof proof-type-exercise" id="id61">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.34</span>
        
    </div><div class="proof-content">
<p>List the four ways to index a vector.</p>
</div></div><div class="proof proof-type-exercise" id="id62">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.35</span>
        
    </div><div class="proof-content">
<p>What is wrong with the expression
<code class="docutils literal notranslate"><span class="pre">x[</span> <span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">0</span> <span class="pre">and</span> <span class="pre">x</span> <span class="pre">&lt;=</span> <span class="pre">1</span> <span class="pre">]</span></code>, where <code class="docutils literal notranslate"><span class="pre">x</span></code> is a numeric vector?
What about <code class="docutils literal notranslate"><span class="pre">x[</span> <span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">0</span> <span class="pre">&amp;</span> <span class="pre">x</span> <span class="pre">&lt;=</span> <span class="pre">1</span> <span class="pre">]</span></code>?</p>
</div></div><div class="proof proof-type-exercise" id="id63">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.36</span>
        
    </div><div class="proof-content">
<p>What does it mean that slicing returns a <em>view</em> of existing data?</p>
</div></div><div class="proof proof-type-exercise" id="id64">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.37</span>
        
    </div><div class="proof-content">
<p>(**) Reflect on the
<a class="reference external" href="https://quoteinvestigator.com/2010/05/26/everything-counts-einstein">famous</a>
saying: <em>not everything that can be counted counts,
and not everything that counts can be counted</em>.</p>
</div></div><div class="proof proof-type-exercise" id="id65">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.38</span>
        
    </div><div class="proof-content">
<p>(**) Being a data scientist can be a frustrating job, especially
when you care for some causes.
Reflect on: <em>some things that count can be counted,
but we will not count them because there’s no budget for them.</em></p>
</div></div><div class="proof proof-type-exercise" id="id66">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.39</span>
        
    </div><div class="proof-content">
<p>(**) Being a data scientist can be a frustrating job, especially
when you care for the truth.
Reflect on: <em>some things that count can be counted,
but we will not count them because some people might be offended
or find it unpleasant.</em></p>
</div></div><div class="proof proof-type-exercise" id="id67">

    <div class="proof-title">
        <span class="proof-type">Exercise 5.40</span>
        
    </div><div class="proof-content">
<p>(**) Assume you were to become the benevolent dictator
of a nation on some remote island. How would you <em>measure</em> if your
people are happy or not?
Let us say that you need to come up with three quantitative measures
(key performance indicators).
What would happen if your policy-making was solely focused
on optimising those KPIs?
What about the same problem but with regard to your company and employees?
Think about what can go wrong in other areas of life.</p>
</div></div><hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footprivacy" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">1</a><span class="fn-bracket">]</span></span>
<p>Nevertheless, we strongly advocate for all information
of concern to the public to be openly available,
so that <em>experienced</em> statisticians can put them to good use.</p>
</aside>
<aside class="footnote brackets" id="footsdbiased" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">2</a><span class="fn-bracket">]</span></span>
<p>(**) Based on the so-called <em>uncorrected for bias</em>
version of the sample variance. We prefer it here for didactical
reasons (simplicity, better interpretability). Plus, it is
the default one in <strong class="program">numpy</strong>.
Passing <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> (<em>delta degrees of freedom</em>)
to <strong class="command">numpy.std</strong> will apply division by <span class="math">\(n-1\)</span> instead of by <span class="math">\(n\)</span>.
When used as an estimator of the distribution’s
standard deviation, the latter has slightly better statistical properties
(which we normally explore in a course on mathematical statistics,
which this one is not). However, we will see later that
the <code class="docutils literal notranslate"><span class="pre">std</span></code> methods in the <strong class="program">pandas</strong> package have <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> by
default. Therefore, we might be interested in setting <code class="docutils literal notranslate"><span class="pre">ddof=0</span></code> therein.</p>
</aside>
<aside class="footnote brackets" id="footiqr15" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">3</a><span class="fn-bracket">]</span></span>
<p>The <span class="math">\(1.5 \mathrm{IQR}\)</span> rule is the most popular
in the statistical literature, but
some plotting software may use different whisker ranges.
See <a class="reference internal" href="520-missingness.html#sec-32iqr"><span class="std std-numref">Section 15.4.1</span></a> for further discussion.</p>
</aside>
<aside class="footnote brackets" id="footboxcox" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">4</a><span class="fn-bracket">]</span></span>
<p>(*) A Box–Cox transformation
can help achieve this in some datasets; see <span id="id20">[<a class="reference internal" href="999-bibliography.html#id146" title="Box, G.E.P. and Cox, D.R. (1964).  An analysis of transformations. Journal of the Royal Statistical Society. Series B (Methodological), 26(2):211–252.">10</a>]</span>.
<a class="reference internal" href="230-distribution.html#chap-distribution"><span class="std std-numref">Chapter 6</span></a> will apply its particular case:
it will turn out that the logarithm of <code class="docutils literal notranslate"><span class="pre">income</span></code>s follow a
normal distribution (hence, <code class="docutils literal notranslate"><span class="pre">income</span></code>s follow a log-normal distribution).
Generally, there is nothing “wrong” or “bad” about data’s not being
normally-distributed. It is just a nice feature to have
in certain contexts.</p>
</aside>
<aside class="footnote brackets" id="footnononstandard" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">5</a><span class="fn-bracket">]</span></span>
<p>(*) The indexer is computed first,
and its <em>value</em> is passed as an argument to the index operator.
Python neither is a symbolic programming language,
nor does it feature any nonstandard evaluation techniques.
In other words, <strong class="command">[...]</strong> does not care how the indexer was
obtained.</p>
</aside>
<aside class="footnote brackets" id="footconttie" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">6</a><span class="fn-bracket">]</span></span>
<p>Where, theoretically, the probability of obtaining
a tie is equal to 0.</p>
</aside>
<aside class="footnote brackets" id="footpandasunique" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id16">7</a><span class="fn-bracket">]</span></span>
<p>Later we will mention <strong class="command">pandas.unique</strong>
which lists the values in the order of appearance.</p>
</aside>
<aside class="footnote brackets" id="footieee754" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">8</a><span class="fn-bracket">]</span></span>
<p>Double precision <code class="docutils literal notranslate"><span class="pre">float64</span></code> format as defined
by the IEEE Standard for Floating-Point Arithmetic (IEEE 754).</p>
</aside>
</aside>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="230-distribution.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title"><span class="section-number">6. </span>Continuous probability distributions</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="210-vector.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title"><span class="section-number">4. </span>Unidimensional numeric data and their empirical distribution</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
              
              
              Copyright &#169; 2022–2023 by <a href="https://www.gagolewski.com/">Marek Gagolewski</a>.
              Some rights reserved. Licensed under <a href='https://creativecommons.org/licenses/by-nc-nd/4.0'>CC BY-NC-ND 4.0</a>.
              Built with <a href="https://sphinx-doc.org/">Sphinx</a>
              and a customised <a href="https://github.com/pradyunsg/furo">Furo</a> theme.
              Last updated on 2023-11-15T11:10:45+1100.
              This site will never display any ads: it is a non-profit project.
              It does not collect any data.
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            In this chapter
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">5. Processing unidimensional data</a><ul>
<li><a class="reference internal" href="#aggregating-numeric-data">5.1. Aggregating numeric data</a><ul>
<li><a class="reference internal" href="#measures-of-location">5.1.1. Measures of location</a><ul>
<li><a class="reference internal" href="#arithmetic-mean-and-median">5.1.1.1. Arithmetic mean and median</a></li>
<li><a class="reference internal" href="#sensitive-to-outliers-vs-robust">5.1.1.2. Sensitive to outliers vs robust</a></li>
<li><a class="reference internal" href="#sample-quantiles">5.1.1.3. Sample quantiles</a></li>
</ul>
</li>
<li><a class="reference internal" href="#measures-of-dispersion">5.1.2. Measures of dispersion</a><ul>
<li><a class="reference internal" href="#standard-deviation-and-variance">5.1.2.1. Standard deviation (and variance)</a></li>
<li><a class="reference internal" href="#interquartile-range">5.1.2.2. Interquartile range</a></li>
</ul>
</li>
<li><a class="reference internal" href="#measures-of-shape">5.1.3. Measures of shape</a></li>
<li><a class="reference internal" href="#box-and-whisker-plots">5.1.4. Box (and whisker) plots</a></li>
<li><a class="reference internal" href="#further-methods">5.1.5. Further methods (*)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#vectorised-mathematical-functions">5.2. Vectorised mathematical functions</a><ul>
<li><a class="reference internal" href="#logarithms-and-exponential-functions">5.2.1. Logarithms and exponential functions</a></li>
<li><a class="reference internal" href="#trigonometric-functions">5.2.2. Trigonometric functions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#arithmetic-operators">5.3. Arithmetic operators</a><ul>
<li><a class="reference internal" href="#vector-scalar-case">5.3.1. Vector-scalar case</a></li>
<li><a class="reference internal" href="#application-feature-scaling">5.3.2. Application: Feature scaling</a><ul>
<li><a class="reference internal" href="#standardisation-and-z-scores">5.3.2.1. Standardisation and z-scores</a></li>
<li><a class="reference internal" href="#min-max-scaling-and-clipping">5.3.2.2. Min-max scaling and clipping</a></li>
<li><a class="reference internal" href="#normalisation-l-2-dividing-by-magnitude">5.3.2.3. Normalisation (<span class="math">\(l_2\)</span>; dividing by magnitude)</a></li>
<li><a class="reference internal" href="#normalisation-l-1-dividing-by-sum">5.3.2.4. Normalisation (<span class="math">\(l_1\)</span>; dividing by sum)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#vector-vector-case">5.3.3. Vector-vector case</a></li>
</ul>
</li>
<li><a class="reference internal" href="#indexing-vectors">5.4. Indexing vectors</a><ul>
<li><a class="reference internal" href="#integer-indexing">5.4.1. Integer indexing</a></li>
<li><a class="reference internal" href="#logical-indexing">5.4.2. Logical indexing</a></li>
<li><a class="reference internal" href="#slicing">5.4.3. Slicing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#other-operations">5.5. Other operations</a><ul>
<li><a class="reference internal" href="#cumulative-sums-and-iterated-differences">5.5.1. Cumulative sums and iterated differences</a></li>
<li><a class="reference internal" href="#sorting">5.5.2. Sorting</a></li>
<li><a class="reference internal" href="#dealing-with-tied-observations">5.5.3. Dealing with tied observations</a></li>
<li><a class="reference internal" href="#determining-the-ordering-permutation-and-ranking">5.5.4. Determining the ordering permutation and ranking</a></li>
<li><a class="reference internal" href="#searching-for-certain-indexes-argmin-argmax">5.5.5. Searching for certain indexes (argmin, argmax)</a></li>
<li><a class="reference internal" href="#dealing-with-round-off-and-measurement-errors">5.5.6. Dealing with round-off and measurement errors</a></li>
<li><a class="reference internal" href="#vectorising-scalar-operations-with-list-comprehensions">5.5.7. Vectorising scalar operations with list comprehensions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exercises">5.6. Exercises</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=aa0d8e41"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/proof.js"></script>
    <script src="../_static/katex.min.js?v=deb2f140"></script>
    <script src="../_static/auto-render.min.js?v=8b9f325c"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    </body>
</html>